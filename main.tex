\documentclass[10pt]{article}

% add links to document
\PassOptionsToPackage{hyphens}{url}\usepackage[hidelinks]{hyperref}

% add some packages
\usepackage{xcolor}
\usepackage[english]{babel}
\usepackage{nameref}
\usepackage{footnote}
\usepackage{refcount}
\usepackage{makecell}
\usepackage[a4paper, total={6in, 10in}]{geometry}
\usepackage{titlesec}
\usepackage{graphicx,import}
\usepackage{setspace}
\usepackage{url}
\usepackage{amsmath,amsfonts,amssymb}
%\usepackage{indentfirst}
\usepackage{float}
\usepackage{pgf}
\usepackage{pdfpages}
\usepackage{svg}
\usepackage{pstricks}
\usepackage{color,soul}
\usepackage{pst-plot}
\usepackage{import}
\usepackage{xifthen}
\usepackage{pdfpages}
\usepackage{transparent}
\usepackage[utf8]{inputenc}
\usepackage{csquotes}
\usepackage[style=verbose-ibid,backend=bibtex]{biblatex}
\usepackage{multirow}
\usepackage{caption}
\usepackage{colortbl}\usepackage{float}
\usepackage{placeins}
\usepackage{dblfloatfix}
\usepackage{tikz}
\usetikzlibrary{positioning}

\usetikzlibrary{math} %needed tikz library


\newcommand*\circled[1]{\tikz[baseline=(char.base)]{
   \node[shape=circle,draw,inner sep=1pt] (char) {#1};}}

\restylefloat{table}

% add more distance between footnotes and the main text
\addtolength{\skip\footins}{2pc plus 5pt}

% italic blockquotes
\renewcommand{\mkbegdispquote}[2]{\itshape}
\renewcommand{\mkbegdispquote}[2]{\openautoquote}
\renewcommand{\mkenddispquote}[2]{\closeautoquote#1#2}

% literature reference
\bibliography{references}

% document settings
\author{Björn Hempel <bjoern@hempel.li>}

% add nice formated tables
\makesavenoteenv{tabular}
\makesavenoteenv{table}

% add automatic numbering
\setcounter{secnumdepth}{5}
\setcounter{tocdepth}{4}
\setlength\bibitemsep{1.5\itemsep}

% some formating settings
\setlength{\parindent}{20pt}
\setlength{\parskip}{5pt}
\titleformat{\paragraph}
{\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}
\titlespacing*{\paragraph}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}

% Footmarks always at the end of the page
\usepackage[bottom]{footmisc}

% allow some special characters
\DeclareUnicodeCharacter{2212}{-}

% pgf figures with images (add function \inputpgf)
\newcommand\inputpgf[2]{{
\let\pgfimageWithoutPath\pgfimage
\renewcommand{\pgfimage}[2][]{\pgfimageWithoutPath[##1]{#1/##2}}
\input{#1/#2}
}}

% import function of tex files
\newcommand{\includetex}[1]{
    \def\svgwidth{\columnwidth}
    \import{images/other/}{#1.pdf_tex}
}

% add language switcher functions \de and \en
\newif\ifen
\newif\ifde
\newcommand{\en}[1]{\ifen#1\fi}
\newcommand{\de}[1]{\ifde#1\fi}

% language switcher
%\detrue
\entrue



% -------------------- %
% Start document %
% -------------------- %
\begin{document}



	% -------------------- %
	% Flyleaf %
	% -------------------- %
	\input{pages/0_1_flyleaf}
	\pagebreak



	% -------------------- %
	% Empty page %
	% -------------------- %
    \newpage\null\thispagestyle{empty}\newpage



	% -------------------- %
	% Abstract %
	% -------------------- %
	\section*{Abstract}
		\de{Neuronale Netze sind außerordentlich gut darin Muster in Daten zu finden. Hierzu müssen diese Netze vorher mit bekannten Datensätzen trainiert und entsprechend angepasst werden. Datensätze sind meist sehr teuer in der Beschaffung und sollten deshalb mit Bedacht und guter Qualität eingesetzt werden. Das Training des Netzes findet unter von vielen verschiedenen Parametern und Verfahrenstechniken statt. Dabei ist darauf zu achten das bestmögliche Modell mit seinen bestmöglichen Parametern zu verwenden. In dieser Arbeit werden gängige moderne Methoden der Bildklassifikation vorgestellt und miteinander verglichen. Das Hauptziel der Arbeit ist es, optimale Parameter und Techniken für die Klassifikation zu finden, die es auch ermöglichen, mit wenig Trainingsdaten ein optimales Modell zu erstellen.}
		\en{Neural networks are extraordinarily good at finding patterns in data. For this purpose, these networks must be trained with known data sets and adapted accordingly. Data sets are usually very expensive to obtain and should therefore be used with care and good quality. The training of the network takes place under many different parameters and process techniques. Care must be taken to use the best possible model with its best possible parameters. In this thesis, common modern methods of image classification will be presented and compared with each other. The main goal of the work is to find optimal parameters and techniques for the classification, which also allow to create an optimal model with little training data.}
	\pagebreak



	% -------------------- %
	% Table of contents %
	% -------------------- %
	\tableofcontents
	\pagebreak


	% -------------------- %
	% Introduction %
	% -------------------- %
	\section{Introduction}
		\de{In dieser Arbeit werden verschiedene Techniken der Bildklassifizierung verglichen. Variable Parameter beim Training werden einen entscheidenden Einfluss auf die Genauigkeit des Modells haben und werden hier im Detail verglichen. Nicht immer ist nur die Genauigkeit ein ausschlaggebender Faktor. Auch die benötigte Rechenzeit, welche notwendig ist das Modell zu bestimmen, soll nicht außer Acht gelassen werden und mit in die Auswertung einbezogen werden. Ich gehe davon aus, dass eine kleine Lernrate verbunden mit vielen Lern-Epochen und entsprechend mehr benötigter Rechenzeit bessere Ergebnisse erzielen werden, als wenige Lernepochen verbunden mit einer hohe Lernrate (langsame Anpassung vs. schnelle Anpassung). Auch gehe ich davon aus, dass eine hohe Qualität und eine größere Menge an Daten das Ergebnis entschieden positiv beeinflussen werden. Neue und komplexere Convolutional Neuronale Netzwerke stufe ich erfolgreicher in der Modellgenauigkeit ein als schön etwas ältere und kleinere Modelle.}
		\en{In this thesis different techniques of image classification are compared. Variable parameters during training will have a decisive influence on the accuracy of the model and are compared here in detail. Not always only the accuracy is a decisive factor. Also the required computing time, which is necessary to determine the model, should not be disregarded and should be included in the evaluation. I assume that a small learning rate combined with many learning epochs and correspondingly more computing time required will achieve better results than a few learning epochs combined with a high learning rate (slow adaptation vs. fast adaptation). I also assume that a high quality and a larger amount of data will have a decidedly positive influence on the result. New and more complex convolutional neural networks are more successful in model accuracy than older and smaller models.}


	% -------------------- %
	% Background %
	% -------------------- %
	\section{Background}

		% -------------------- %
		% Image Classification %
		% -------------------- %
		\subsection{Image Classification}
			\de{Klassifizierungen sind ein Prozess der Identifizierung, zu welcher Klasse ein unbeobachtetes Objekt gehört. Hierbei können eine Reihe von vordefinierten Klassen vorgegeben und anhand deren Eigenschaften versucht werden unbekannte und bisher unbeobachtete Objekt einzuordnen. Bei der Bildklassifizierung wird analog vorgegangen. Bei den zuvor genannten Objekten handelt es sich nun schlichtweg um Bilder.}
			\en{Classifications are a process of identifying to which class an unobserved object belongs. A number of predefined classes can be specified and, based on their properties, an attempt can be made to classify unknown and previously unobserved objects. The procedure for image classification is similar. The previously mentioned objects are now simply images.}

			\begin{figure}[H]
				\centering
				\includegraphics[width=0.4\textwidth]{images/cat_dog}
				\caption[Is it a dog or a cat?]{Is it a dog or a cat?\footnotemark}
				\label{fig:cat_or_dog}
			\end{figure}
			\footnotetext{Source: \url{https://towardsdatascience.com/image-classifier-cats-vs-dogs-with-convolutional-neural-networks-cnns-and-google-colabs-4e9af21ae7a8}}

			\de{Lange Zeit galt die automatische Erkennung von Objekten, Personen und Szenen in Bildern durch Computer als unmöglich. Die Komplexität schien zu groß, als dass man sie einem Algorithmus programmatisch beibringen könnte. Bis noch vor einigen Jahrzehnten hat man so versucht Bildklassifikation durch manuell entwickelte Algorithmen zu erreichen. Die automatisierte Klassifikation anhand von vorgegebenen und vorklassifizierten Bildern und dem automatisierten Erstellen von Modellen war ein neuer Schritt in eine neue Vorgehensweise. Die dabei entwickelten neuronale Netze spielten eine gewaltige Rolle und änderten dramatisch die Art der Herangehensweise! Mittlerweile ist die Bilderkennung ein weit verbreitetes Anwendungsgebiet des maschinellen Lernens. Häufig werden für Bilder sogenannte "Convolutional Neural Networks\footnote{Convolutional neural network, Wikipedia contributors, January 31, 2020, \url{https://en.wikipedia.org/wiki/Convolutional_neural_network}}" or "ConvNets" are often used for images.}
			\en{For a long time, the automatic recognition of objects, people and scenes in images by computers was considered impossible. The complexity seemed too great to be programmatically taught to an algorithm. Until a few decades ago, attempts were made to achieve image classification by manually developed algorithms. Automated classification based on given and pre-classified images and the automated creation of models was a new step into a new approach. The neural networks developed in this process played a huge role and dramatically changed the way of approach! In the meantime, image recognition has become a widespread application area of machine learning. So-called "Convolutional Neural Networks\footnote{Convolutional neural network, Wikipedia contributors, January 31, 2020, \url{https://en.wikipedia.org/wiki/Convolutional_neural_network}}" or "ConvNets" are often used for images.}

			\de{Der Bildklassifizierungsalgorithmus nimmt ein Bild als Eingabe und klassifiziert es in eine der Ausgabekategorien. Deep Learning hat den Bereich der Bildklassifizierung revolutioniert und großartige Ergebnisse erzielt. Verschiedene Deep Learning Netzwerke, wie ResNet, DenseNet, Inception, etc. wurden als hochpräzise Netzwerke für die Bildklassifikation entwickelt. Gleichzeitig wurden Bilddatensätze angelegt, um getaggte Bilddaten zu erfassen. Diese werden jetzt vorrangig dazu verwendet um bestehende Netzwerke zu trainieren und alljährliche Challenges zu veranstalten, welche sich mit den bisher bekannten und schon entwickelten Modellgenauigkeiten messen. ImageNet ist ein solch großer Datensatz mit mehr als 11 Millionen Bildern und über 11.000 Kategorien. Wenn ein Netzwerk einmal mit ImageNet-Daten trainiert wurde, kann es durch einfache Neuanpassung oder Optimierung mit anderen Datensätzen verallgemeinert werden. Bei diesem Transfer-Lernansatz wird ein Netzwerk mit Gewichten initialisiert, welche aus einem zuvor trainierten Netzwerk stammen. Dieses zuvor initialisierte Netzwerk wird nun für eine neue Bildklassifikationsaufgabe lediglich entsprechend angepasst.}
			\en{The image classification algorithm takes an image as input and classifies it into one of the output categories. Deep Learning has revolutionized the field of image classification and has achieved great results. Various Deep Learning networks, such as ResNet, DenseNet, Inception, etc. have been developed as high-precision networks for image classification. At the same time, image data sets were created to capture tagged image data. These are now primarily used to train existing networks and to organize annual challenges that compete with the model accuracies already known and developed. ImageNet is such a large data set with more than 11 million images and over 11,000 categories. Once a network has been trained with ImageNet data, it can be generalized with other data sets by simple re-compilation or optimization. In this transfer learning approach, a network is initialized with weights that come from a previously trained network. This previously initialized network is now simply adapted for a new image classification task.}

			\de{Die hier zugrunde liegende Arbeit beschäftigt sich hauptsächlich mit überwachtem Lernen, bei dem ein mathematisches Modell aufgrund bestehender bekannter Datensätze trainiert wird. Das Ziel des trainierten Modells ist es dabei auch für unbekannte Bilder bestmögliche Vorhersagen zu treffen. Diese bekannten Datensätze werden meist händisch erstellt (Ontologe), automatisiert aufgrund bekannter Tatsachen bestimmt oder auch in einem halbautomatischen Prozess ermittelt.}
			\en{The underlying work here is mainly concerned with supervised learning, in which a mathematical model is trained based on existing known data sets. The goal of the trained model is to make best possible predictions even for unknown images. These known data sets are usually created manually (ontologist), automatically determined based on known facts or determined in a semi-automatic process.}
			
		% -------------------- %
		% Deductive approach %
		% -------------------- %
		\subsubsection{Deductive approach}
		\label{sec:section_deductive_approach}
			\de{Seit den späten 1960er Jahren hat man versucht, Bilder mit selbstgeschriebenen Algorithmen zu klassifizieren. Dieser Teil der Computer Vision beschäftigt sich mit Techniken wie Bildentstehung, Bildbearbeitung und Bildsegmentierung. Im Bereich der Bildverarbeitung reihen sich bekannte Verfahren wie Kantenerkennungen, Merkmalsdetektoren, Randverknüpfungen, Kontrastverbesserungen, etc.\footnote{Szeliski, R.: Computer Vision: Algorithms and Applications,  Springer Science Business Media, 10 (2010)\label{springer_10}} Allen Techniken gemein ist die Verwendung des deduktiven Ansatzes. Beim deduktiven Ansatz erstellt man Regeln (Merkmalsdetektoren), welche das gewünschte Ergebnis vorhersagen sollen. Diese Regeln werden vorgegeben und beschrieben und erlauben damit später eine Klassifizierung von unbekannten Objekten. Da das Modell und sein Algorithmus hinreichend bekannt ist, wird dieses Verfahren White-Box-Verfahren genannt.}
			\en{Since the late 1960s, attempts have been made to classify images with self-written algorithms. This part of Computer Vision deals with techniques such as image creation, image processing and image segmentation. In the field of image processing, well-known techniques such as edge detection, feature detectors, edge linking, contrast enhancement, etc. are used\footnote{Szeliski, R.: Computer Vision: Algorithms and Applications,  Springer Science Business Media, 10 (2010)\label{springer_10}}. Common to all techniques is the use of the deductive approach. With the deductive approach, one creates rules (feature detectors) which are supposed to predict the desired result. These rules are given and described and thus allow later classification of unknown objects. Since the model and its algorithm are sufficiently well known, this procedure is called white-box procedure.}

			\begin{figure}[H]
				\begin{center}
					\scalebox{1.0}{\includetex{deductive_approach}}
				\end{center}
				\caption{Deductive approach}
				\label{fig:overview_deductive_approach}
			\end{figure}

			\de{}

		% -------------------- %
		% Inductive approach %
		% -------------------- %
		\subsubsection{Inductive approach}
		\label{sec:section_inductive_approach}
			\de{Der induktive Ansatz hingegen verfolgt einen anderen Ansatz Bilder zu klassifizieren. Das Ziel ist nicht die Vorgabe einer Regel, sondern das Vorgehen aus schon bekannten einzelnen Objekten eine Regel (Modell) automatisiert zu erlernen. Ein Modell meist eine komplexe Funktion und eine mathematische Abbildung eines Raumes (VC Dimension\footnote{Vapnik–Chervonenkis dimension, Wikipedia contributors, January 31, 2020, \url{https://en.wikipedia.org/wiki/Vapnik\%E2\%80\%93Chervonenkis_dimension}}), in welcher einzelne Objekte mit ihren Eigenschaften abgebildet und getrennt werden können. Das Modell wird Stück für Stück den bekannten Objekten so angepasst, dass der Eingabewert dem Ausgabewert entspricht bzw. weitgehend entspricht (Backpropagation). Das Ziel ist es mit diesem Modell eine Funktion zu erstellen, welche in der Lage ist auch unbekannte Objekte bestmöglichst zu klassifizieren. Da der Raum dieses Modell meist fern der Vorstellungskraft und der Erklärungsmöglichkeit liegt, wird dieses Verfahren auch Black-Box-Verfahren genannt. Der hier beschriebene Vorgang wird meist bei jeder Art von \hyperref[sec:section_supervised_classification]{überwachtem Lernen} angewendet und ist ein Teil des \hyperref[sec:section_machine_learning]{maschinellem Lernens}.}
			\en{The inductive approach, on the other hand, takes a different approach to classifying images. The goal is not to specify a rule, but to learn a rule (model) automatically from already known individual objects. A model is usually a complex function and a mathematical representation of a space (VC dimension\footnote{Vapnik–Chervonenkis dimension, Wikipedia contributors, January 31, 2020, \url{https://en.wikipedia.org/wiki/Vapnik\%E2\%80\%93Chervonenkis_dimension}}), in which individual objects with their properties can be mapped and separated. The model is adapted piece by piece to the known objects in such a way that the input value corresponds to the output value or corresponds to a large extent (backpropagation). The goal is to create a function with this model, which is able to classify unknown objects in the best possible way. Because the space of this model is mostly far away from the imagination and the possibility of explanation, this procedure is also called black box procedure. The procedure described here is mostly used for any kind of \hyperref[sec:section_supervised_classification]{supervised learning} and is a part of \hyperref[sec:section_machine_learning]{machine learning}.}

			\begin{figure}[H]
				\begin{center}
					\scalebox{1.0}{\includetex{inductive_approach}}
				\end{center}
				\caption{Inductive approach}
				\label{fig:overview_inductive_approach}
			\end{figure}

		% -------------------- %
		% Balanced training data set %
		% -------------------- %
		\subsubsection{Balanced training data set}
		\label{sec:section_balanced_training_data_set}
			\de{Neuronale Netze haben in den letzten Jahren enorme Fortschritte im Bereich der Mustererkennung gemacht. Dabei ist ein entscheidender Faktor, dass die Daten zum Lernen eine hohe Qualität und eine einfache Verarbeitung für das Netzwerk aufweisen müssen. Falsch klassifizierte oder irrelevante Daten könnten dazu führen, dass das Netzwerk was Falsches lernt. Das gilt auch für eine nicht vorhandene bzw. nicht geeignete Vorverarbeitung.}
			\en{Neural networks have made enormous progress in the field of pattern recognition in recent years. A decisive factor is that the data for learning must be of high quality and easy for the network to process. Wrongly classified or irrelevant data could cause the network to learn something wrong. This also applies to non-existent or unsuitable pre-processing\autocite{osinga2019data}.}

			\de{Mit dem Beginn eines Klassifizierungsprojektes steht die Frage was genau man klassifizieren möchte und wie umfangreich die Klassifzierung ausfallen soll. Angenommen man möchte verschiedene Klassen von Essen identifizieren, so könnten das Klassen wie Pizza, Burger, Donuts und Lasagne sein (etc.). Zu diesen Klassen benötigt man nun eine große Anzahl an Bildern. Diese Daten sollten im Idealfall die Realität möglichst gut widerspiegeln. Eine große Variation ist von Vorteil (ausbalancierter Datenset): verschiedene Blickwinkel, Größe, Position, Farbhelligkeiten, Variationen, Anzahl, etc. Bilder von z.B. nur einer Farbhelligkeit oder nur einem Blickwinkel sollten vermieden werden. Sind die Daten nicht ausbalanciert, so müssen diese entsprechend korrigiert werden: z.B. durch Hinzufügen weiterer Daten, Bildverarbeitung oder durch Entfernen von Daten, welche für eine Unausgewogenheit sorgen. Weiterhin sollten die ausgewählten Klassen untereinander klar optisch trennbar sein. Sind sich zwei Klassen optisch sehr ähnlich und selbst durch einen Menschen nicht wirklich unterscheidbar, sollte darüber nachgedacht werden diese zusammenzufassen (z.B. "burger" und "veggie burger"):}
			\en{With the beginning of a classification project the question is what exactly you want to classify and how extensive the classification should be. Assuming you want to identify different classes of food, this could be classes like pizza, burgers, donuts and lasagna (etc.). For these classes you now need a large number of images. Ideally, this data should reflect reality as well as possible. A large variation is advantageous (balanced data set): different viewing angles, size, position, colour brightness, variations, number, etc. Images of e.g. only one colour brightness or only one viewing angle should be avoided. If the data are not balanced, they must be corrected accordingly: e.g. by adding further data, image processing or by removing data that causes an imbalance. Furthermore, the selected classes should be clearly optically separable from each other. If two classes are visually very similar and not really distinguishable even by a human, consideration should be given to combining them (e.g. "burger" and "veggie burger"):}

			\begin{figure}[H]
				\centering
				\includegraphics[width=0.19\textwidth]{images/data/burger/burger28.jpg}
				\includegraphics[width=0.19\textwidth]{images/data/burger/burger77.jpg}
				\includegraphics[width=0.19\textwidth]{images/data/burger/burger89.jpg}
				\includegraphics[width=0.19\textwidth]{images/data/burger/burger162.jpg}
				\includegraphics[width=0.19\textwidth]{images/data/burger/burger449.jpeg}
				\caption[Example pictures of a burger class]{Example pictures of a burger class}
				\label{fig:class_burger}
			\end{figure}

			\begin{figure}[H]
				\centering
				\includegraphics[width=0.19\textwidth]{images/data/donut/donut116.jpg}
				\includegraphics[width=0.19\textwidth]{images/data/donut/donut155.jpg}
				\includegraphics[width=0.19\textwidth]{images/data/donut/donut176.jpg}
				\includegraphics[width=0.19\textwidth]{images/data/donut/donut205.jpg}
				\includegraphics[width=0.19\textwidth]{images/data/donut/donut440.jpg}
				\caption[Example pictures of a donut class]{Example pictures of a donut class}
				\label{fig:class_donut}
			\end{figure}

			\begin{figure}[H]
				\centering
				\includegraphics[width=0.19\textwidth]{images/data/pizza/pizza73.png}
				\includegraphics[width=0.19\textwidth]{images/data/pizza/pizza76.jpg}
				\includegraphics[width=0.19\textwidth]{images/data/pizza/pizza92.jpg}
				\includegraphics[width=0.19\textwidth]{images/data/pizza/pizza108.jpg}
				\includegraphics[width=0.19\textwidth]{images/data/pizza/pizza239.jpg}
				\caption[Example pictures of a pizza class]{Example pictures of a pizza class}
				\label{fig:class_pizza}
			\end{figure}

			\de{An Daten zu gelangen ist oftmals nicht so einfach. Jede Datenquelle hat ihre eigenen Besonderheiten. Eine Möglichkeit an Daten zu gelangen wäre ein automatische Crawling von Bilddatenbanken, Suchmaschinen oder Rezensionen, in welchen Bilder vorkommen. Ein gewisses Maß an Kreativität ist von Vorteil:}
			\en{Accessing data is often not that easy. Every data source has its own special features. One way to access data would be an automatic crawling of image databases, search engines or reviews in which images appear. A certain amount of creativity is advantageous:}

			\begin{itemize}
				\item Google
				\item Bing
				\item Flickr
				\item TripAdvisor
				\item etc.
			\end{itemize}
			
			\de{Die wahrscheinlich teuerste Variante an Daten zu gelangen ist die händische Suche und Klassifizierung durch z.B. einen Ontologen. Dieser beurteilt und sucht verschiedenen Bilder und ordnet diese händisch in die entsprechenden Klassen ein. Auch eine kombinierte Variante ist möglich und wahrscheinlich zu bevorzugen: Automatisches Crawling und händisches aussortieren falscher, ungünstiger oder irrelevanter Bilder.}
			\en{Probably the most expensive way to obtain data is to search and classify them manually, e.g. by an ontologist. The ontologist evaluates and searches for different images and manually classifies them in the appropriate classes. A combined variant is also possible and probably preferable: automatic crawling and manual sorting out of incorrect, unfavorable or irrelevant images.}

		% -------------------- %
		% Training, test and evaluation data set %
		% -------------------- %
		\subsubsection{Training, test and evaluation data set}
		\label{sec:section_training_test_and_evaluation}
			\de{Vor dem Beginn mit dem Training von ausbalancierten Bildern müssen diese in einen Trainings-, einen Test- und eventuell in einen Validierungsdatensatz aufgeteilt werden. Dies ist notwendig, da neuronale Netze zu einem Teil nicht verallgemeinern, sondern auswendig lernen werden (overfitting\footnote{``Overfitting'', Wikipedia contributors, January 31, 2020, \url{https://en.wikipedia.org/wiki/Overfitting}}). Die Idee ist es mit einem Trainingsdatensatz zu trainieren, während mit dem Validierungsdatensatz die Allgemeingültigkeit des Netzes und seiner Parameter überwacht wird. Anhand der Ergebnisse werden zur Laufzeit Anpassungen vorgenommen. Da die Anpassung der Parameter anhand der Testdaten vorgenommen wird, gibt es noch einen unabhängigen Testdatensatz, welcher eine erneute Überprüfung des Modells auf bisher unbeteiligte Daten vornimmt. Dieser stellt sicher, dass nicht versehentlich Hyperparameter nur speziell für den Validierungsdatensatz optimiert werden\autocite{osinga2019data}. Die Verwendung des Testdatensatz ist optional und simuliert das Modell unter realen Bedingungen. Ist die Anzahl der Daten begrenzt und kann dieser Datensatz z.B. auch dem Trainingsdatensatz hinzugefügt werden. In dieser Arbeit wird auf den Testdatensatz verzichtet und sämtliche Auswertungen beziehen sich auf den Validierungsdatensatz.}
			\en{Before starting the training of balanced images, they must be divided into a training, a test and possibly a validation data set. This is necessary because neural networks will not generalize to some extent, but will learn by heart (overfitting\footnote{``Overfitting'', Wikipedia contributors, January 31, 2020, \url{https://en.wikipedia.org/wiki/Overfitting}}). The idea is to train with a training data set, while the validation data set is used to monitor the general validity of the network and its parameters. Based on the results, adjustments are made at runtime. Since the adjustment of the parameters is carried out using the test data, there is also an independent test data set, which carries out a renewed check of the model for previously uninvolved data. This ensures that hyperparameters are not inadvertently optimized for the validation data set only\autocite{osinga2019data}. The use of the test data set is optional and simulates the model under real conditions. If the number of data is limited, this data record can also be added to the training data record, for example. In this thesis, the test data set is not used and all evaluations refer to the validation data set.}

			\de{Eine optimale Aufteilung des Trainings- und Validierungsdatensatzes ist abhängig von dem vorliegenden Klassifizierungsproblem und die Anzahl der Daten, welche zur Verfügung stehen. In dieser Arbeit wird ein Verhältnis aus 80 Prozent Trainingsdaten und 20 Prozent Validierungsdaten verwendet, sofern nicht anders angegeben.}
			\en{An optimal division of the training and validation data set depends on the existing classification problem and the amount of data available. In this paper a ratio of 80 percent training data and 20 percent validation data is used, unless otherwise stated.}

			\de{\hl{Hier muss die Frage noch geklärt werden warum 80 Prozent Trainingsdaten und 20 Prozent Validierungsdaten verwendet werden. Gibt es ein Paper bzw. eine Studie dazu? Oder ist noch ein Test erforderlich?}}
			\en{\hl{The question of why 80 percent training data and 20 percent validation data are used remains to be clarified. Is there a paper or a study on this? Or is another test required?}}			

		% -------------------- %
		% Methods of machine learning %
		% -------------------- %
		\subsubsection{Methods of machine learning}
		\label{sec:section_methods_of_machine_learning}
			\de{Je nach Art und Vorgehensweise der Überwachung des Trainings lassen sich verschiedene Machine-Learning-System einordnen. Dabei wird unterschieden, welche Art von Daten uns vorliegen oder diese selbst bestimmt werden müssen.}
			\en{Different machine learning systems can be classified according to the type and procedure of monitoring the training. A distinction is made between the type of data we have or the data we need to determine ourselves.}

			% -------------------- %
			% Supervised learning %
			% -------------------- %
			\paragraph{Supervised learning}
			\label{sec:section_supervised_learning}
				\de{Das überwachte Lernen bezieht sich auf ein maschinelles Lernen mit bekannten Trainingsdatensätzen (siehe auch Kapitel ``induktiver Ansatz''\hyperref[sec:section_inductive_approach]). Der Lernprozess wiederrum bezieht sich auf die Fähigkeit einer künstlichen Intelligenz, Regelmäßigkeiten und Muster zu reproduzieren. Die Ergebnisse sind durch Naturgesetze oder Expertenwissen bekannt und werden für die Lehre des Systems verwendet, in dem ein Trainingsset erstellt wird, welcher die gewünschten Lösungen enthält. Man nennt dies auch gelabelte Daten. Der Lernalgorithmus versucht nun epochenweise eine Hypothese zu finden, die eine möglichst genaue Vorhersagen auf unbekannten Daten ermöglicht. Eine Hypothese ist in diesem Fall ein Bild, das jedem Eingabewert (das Bild selbst) den angenommenen Ausgabewert (die vorhergesagte Klasse) zuordnet. Diese Arbeit macht ausgiebigen Gebrauch von überwachtem Lernen.}
				\en{Supervised learning refers to machine learning with known training data sets (see also chapter ``inductive approach''\hyperref[sec:section_inductive_approach]). The learning process in turn refers to the ability of an artificial intelligence to reproduce regularities and patterns. The results are known by laws of nature or expert knowledge and are used to teach the system by creating a training set containing the desired solutions. This is also called labelled data. The learning algorithm now tries to find a hypothesis epoch by epoch, which allows the most accurate predictions on unknown data. A hypothesis in this case is an image that assigns the assumed output value (the predicted class) to each input value (the image itself). This work makes extensive use of supervised learning.}
	
				\de{Beim Überwachten Lernen wird einer Klassifizierungsfunktion (meist ein künstliches neuronales Netz) ein Eingangsvektor zugeführt. Der Eingangsvektor erzeugt mit Hilfe der Klassifizierungsfunktion einen Ausgabevektor, die dieses neuronale Netz in seinem aktuellen Zustand produziert\footnote{Das neuronale Netzwerk besteht aus vielen (meist Millionen) Parametern, welche während des Lernprozesses angepasst werden können, um den Fehler zu minimieren.}. Dieser Wert wird mit dem Wert verglichen, den es eigentlich ausgeben soll. Der Vergleich des Soll- und Istzustandes gibt Auskunft wie und in welcher Form Änderungen am Netzwerk vorgenommen werden müssen, um dem Istzustand weiter anzugleichen und den Fehler zu minimieren. Für künstliche neuronale Netzwerke ohne versteckter Schicht (einlagiges Perzeptron\footnote{``Perceptron'', Wikipedia contributors, February 2, 2020, \url{https://en.wikipedia.org/wiki/Perceptron}}) kann die Delta-Regel\footnote{``Least mean squares'' filter also known as ``delta rule'', Wikipedia contributors, February 2, 2020, \url{https://en.wikipedia.org/wiki/Least_mean_squares_filter}} für die Korrektur vorgenommen werden. Bei Netzwerken mit einer oder mehreren versteckten Schichten verwendet man Backpropagation\footnote{``Backpropagation'', Wikipedia contributors, February 2, 2020, \url{https://en.wikipedia.org/wiki/Backpropagation}} um den Fehler zu minimieren. Backpropagation ist eine Verallgemeinerung der Delta-Regel.}
				\en{In supervised learning, an input vector is fed to a classification function (usually an artificial neural network). The input vector generates an output vector using the classification function, which produces this neural network in its current state\footnote{The neural network consists of many (usually millions) parameters, which can be adjusted during the learning process to minimize the error.}. This value is compared with the value that it should actually output. The comparison of the nominal and actual state provides information on how and in what form changes must be made to the network in order to further approximate the actual state and minimize the error. For artificial neural networks without a hidden layer (single-layer perceptron\footnote{``Perceptron'', Wikipedia contributors, February 2, 2020, \url{https://en.wikipedia.org/wiki/Perceptron}}), the delta rule\footnote{``Least mean squares'' filter also known as ``delta rule'', Wikipedia contributors, February 2, 2020, \url{https://en.wikipedia.org/wiki/Least_mean_squares_filter}} for correction can be applied. For networks with one or more hidden layers backpropagation\footnote{``Backpropagation'', Wikipedia contributors, February 2, 2020, \url{https://en.wikipedia.org/wiki/Backpropagation}} is used to minimize the error. Backpropagation is a generalization of the delta rule.}
				
				\de{Das neuronale Netzwerke ist nur ein Algorithmus aus der Kategorie der überwachten Lernalgorithmen. Der Vollständigkeit hier noch eine Liste von weiteren Verfahren:}
				\en{The neural network is only one algorithm from the category of supervised learning algorithms. For completeness here is a list of further algorithms:}
				
				\begin{itemize}
					\item k-nearest neighbors\footnote{``k-nearest neighbors algorithm'', Wikipedia contributors, February 2, 2020, \url{https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm}}
					\item Linear regression\footnote{``Linear regression'', Wikipedia contributors, February 2, 2020, \url{https://en.wikipedia.org/wiki/Linear_regression}}
					\item Logistic regression\footnote{``Logistic regression'', Wikipedia contributors, February 2, 2020, \url{https://en.wikipedia.org/wiki/Logistic_regression}}
					\item Support-vector machine\footnote{``Support-vector machine'', Wikipedia contributors, February 2, 2020, \url{https://en.wikipedia.org/wiki/Support-vector_machine}}
					\item Random forest\footnote{``Random forest'', Wikipedia contributors, February 2, 2020, \url{https://en.wikipedia.org/wiki/Random_forest}}
					\item etc.
				\end{itemize}
		
			% -------------------- %
			% Unsupervised learning %
			% -------------------- %
			\paragraph{Unsupervised learning}
			\label{sec:section_unsupervised_learning}
				\de{Beim unüberwachtem Lernen versucht man auch ohne gelabelte Daten an eine Kenntnis von Mustern zu erlangen. Angenommen man hätte mehrere Bilder von Burgern, Pizza und Donuts, welche sich unsortiert in einem Datenset befinden. Das unüberwachte Lernen versucht nun Ähnlichkeiten zu finden, um diese Bilder zu gruppieren. Im besten Fall erhält man am Ende drei unbenannte Gruppen \(A\), \(B\) und \(C\). Analysten werden sich diese Gruppen im Nachgang genauer anschauen und ein Fazit daraus ziehen, sofern dies möglich ist: Gruppe \(A\) sind Burger, Gruppe \(B\) sind Pizzen, etc.}
				\en{In unsupervised learning, one tries to gain knowledge of patterns even without labelled data. Suppose you have several pictures of burgers, pizza and donuts, which are unsorted in a data set. Unsupervised learning now tries to find similarities in order to cluster these images. In the best case you get three unnamed groups \(A\), \(B\) and \(C\) at the end. Analysts will take a closer look at these groups afterwards and draw a conclusion if possible: Group \(A\) is burgers, group \(B\) is pizzas, etc. }
				
				\de{\noindent Folgende unüberwachte Lernalgorithmen können zur Gruppierung verwendet werden:}
				\en{\noindent The following unsupervised learning algorithms can be used for clustering:}
				
				\begin{itemize}
					\item k-means\footnote{``k-means clustering'', Wikipedia contributors, February 2, 2020, \url{https://en.wikipedia.org/wiki/K-means_clustering}}
					\item Hierarchical clustering\footnote{``Hierarchical clustering'', Wikipedia contributors, February 2, 2020, \url{https://en.wikipedia.org/wiki/Hierarchical_clustering}}
					\item Expectation–maximization \footnote{``Expectation–maximization algorithm'', Wikipedia contributors, February 2, 2020, \url{Expectation–maximization algorithm}}
					\item etc.
				\end{itemize}
			
				\de{Eine Technik, die hierarchische Clusteranalyse, wird später verwendet um die Einführung von Hierarchien zu erleichtern. Für die allgemeine Analyse, den Finden von optimalen Parametern für das Lernen von Modellen, wird diese Art des Lernens in dieser Arbeit nicht verwendet.}
				\en{One technique, hierarchical clustering, is used later to facilitate the introduction of hierarchies. For the general analysis, the finding of optimal parameters for learning models, this kind of learning is not used in this thesis.}

			% -------------------- %
			% Reinforcement learning %
			% -------------------- %
			\paragraph{Reinforcement learning}
			\label{sec:section_reinforcement_learning}
				\de{Reinforcement learning\footnote{``Reinforcement learning'', Wikipedia contributors, January 31, 2020, \url{https://en.wikipedia.org/wiki/Reinforcement_learning}} ist eine Art des maschinellen Lernens, bei der ein Agent selbstständig die bestmögliche Strategie für die Erreichung eines Zieles erlernt. Für die Erreichung des Ziels sind Aktionen notwendig, welche zu bestimmten Zeitpunkten Belohnungen hervorbringen. Diese Belohnungen können auch negative sein (Bestrafung). Anhand dieser Belohnungen gilt es in Summe den bestmöglichen Belohnungswert zu erzielen. Bei der Klassifizierung von Bildern ist diese Art des Lernens nicht relevant, weshalb hier auch nicht weiter darauf eingegangen wird.}
				\en{Reinforcement learning\footnote{``Reinforcement learning'', Wikipedia contributors, January 31, 2020, \url{https://en.wikipedia.org/wiki/Reinforcement_learning}} is a type of machine learning in which an agent independently learns the best possible strategy for achieving a goal. To achieve the goal, actions are necessary which produce rewards at certain points in time. These rewards can also be negative (punishment). Based on these rewards, the aim is to achieve the best possible reward value. This type of learning is not relevant for the classification of images, which is why it will not be discussed further here.}



		% -------------------- %
		% Classification Metrics %
		% -------------------- %
		\subsubsection{Classification Metrics and confusion matrix}
			\de{Die Wahl der richtigen Metrik ist bei der Bewertung von Modellen des maschinellen Lernens von entscheidender Bedeutung. Metriken werden zur Überwachung und Messung der Leistung eines Modells während des Trainings und des Tests verwendet. Im nachfolgenden werden einige wichtige Metriken erklärt.}
			\en{Choosing the right metric is crucial in evaluating machine learning models. Metrics are used to monitor and measure the performance of a model during training and testing. Some important metrics are explained below.}

			% -------------------- %
			% Confusion Matrix %
			% -------------------- %
			\paragraph{Confusion Matrix}
			 	\de{Die Confusion Matrix ist eine spezielle quadratische Matrix auf dem Gebiet des maschinellen Lernens, das die Visualisierung der Leistung eines Vorhersage-Modells ermöglicht. Jede Zeile der Matrix repräsentiert die tatsächliche Klasse, während jede Spalte die Anzahl oder eine Zahlenangaben in Prozent der vorhergesagten Klasse angibt (oder umgekehrt)\footnote{``Confusion matrix'', Wikipedia contributors, February 5, 2020, \url{https://en.wikipedia.org/wiki/Confusion_matrix}}:}
			 	\en{The Confusion Matrix is a special quadratic matrix in the field of machine learning that allows the visualization of the performance of a predictive model. Each row of the matrix represents the actual class, while each column indicates the number or a numerical value as a percentage of the predicted class (or vice versa)\footnote{``Confusion matrix'', Wikipedia contributors, February 5, 2020, \url{https://en.wikipedia.org/wiki/Confusion_matrix}}:}

				\begin{table}[htb]
					\centering
					{\def\arraystretch{2}\tabcolsep=5pt
						\begin{tabular}{cc|c|c|c|c|}
							\cline{3-6}
							& & \multicolumn{4}{c|}{\textbf{predicted}} \\ \cline{3-6} 
							& & \boldmath\(class_1\) & \boldmath\(class_2\) & \textbf{\ldots} & \boldmath\(class_n\) \\ \hline
							\multicolumn{1}{|l|}{\multirow{4}{*}{\rotatebox{90}{\textbf{actual}}}} & \boldmath\(class_1\) & \(TP\)                  & \multicolumn{3}{c|}{\(FN\)} \\ \cline{2-6} 
							\multicolumn{1}{|c|}{} & \boldmath\(class_2\) & \multirow{3}{*}{\(FP\)} & \multicolumn{3}{c|}{\multirow{3}{*}{\(TN\)}} \\ \cline{2-2}
							\multicolumn{1}{|c|}{} & \textbf{\ldots} & & \multicolumn{3}{c|}{}                   \\ \cline{2-2}
							\multicolumn{1}{|c|}{} & \boldmath\(class_n\) & & \multicolumn{3}{c|}{}                   \\ \hline
						\end{tabular}
					}
					\captionof{table}{Confusion matrix}\label{tbl:table_confusion_matrix}
				\end{table}

			 	\de{Zum Schluß besitzt die Confusion Matrix folgenden Aufbau, wobei die Anzahl von Elementen in der Klasse \(C_{i,P}\) vorhergesagt wurde, obwohl (\(\boldsymbol{\cong}\)) es hätte Klasse \(C_{j,A}\) sein müssen:}
				\en{Finally, the Confusion Matrix has the following structure, where the number of elements in the class \(C_{i,P}\) was predicted although (\(\boldsymbol{\cong}\)) it should have been class \(C_{j,A}\):}

				\begin{equation}
					\boldsymbol{M}_{confusion} = \begin{bmatrix}
						\#C_{1,P}\boldsymbol{\cong} C_{1,A} & \dots & \#(C_{n,P}\boldsymbol{\cong} C_{1,A}) \\
						\vdots & \ddots & \vdots \\
						\#(C_{1,P}\boldsymbol{\cong} C_{n,A}) & \dots & \#(C_{n,P}\boldsymbol{\cong} C_{n,A})
					\end{bmatrix} = (a_{nn})
				\end{equation}

			% -------------------- %
			% Accuracy %
			% -------------------- %
			\paragraph{Accuracy}
				\de{Die \textbf{Top-1-Genauigkeit} ist wahrscheinlich die wichtigste Genauigkeit. Sie sagt sagt aus, zu wieviel Prozent die jeweils beste Aussage des Modells auf die Daten des Validierungssets mit der erwarteten Klasse übereinstimmt.}
				\en{\textbf{Top-1 accuracy} is probably the most important accuracy. It tells you the percentage of the model's best prediction of the data in the validation set that matches the expected class.}

				\begin{equation}
					Accuracy = {{TP + TN} \over {TP + TN + FP + FN}} = {{\sum_{i,j=1}^{n} a_{ij}} \over {\sum_{i=1}^{n} \sum_{j=1}^{n} a_{ij}}} = {{Correct_{all}} \over {CorrectPossible_{all}}}
				\end{equation}

				\de{Die \textbf{Top-5-Genauigkeit} ist eine weitere Genauigkeitsangabe. Jedoch wird hier nicht nur der beste Treffer einbezogen, sondern auch die nächsten weiteren vier. Sobald die richtige Klasse innerhalb der ersten fünf vorhergesagten Klassen gefunden werden kann, so ist auch diese Vorhersage wahr:}
				\en{The \textbf{Top 5 Accuracy} is another accuracy specification. However, not only the best hit is included here, but also the next four. As soon as the correct class can be found within the first five predicted classes, this prediction is also true:}
				
				\begin{equation}
					Accuracy_{top-5} = {{CorrectWithinTheBest5Classes_{all}} \over {CorrectPossible_{all}}}
				\end{equation}

				\de{Die Genauigkeit des gesamten Modells ist eine gute Aussagekraft über die Leistungsfähigkeit des Modells. Ein Problem tritt jedoch in Extremfällen auf, bei denen nicht mehr zuverlässig Annahmen gemacht werden können. Zum Beispiel wenn man es mit einem unbalancierten Datensatz zu tun hat\autocite{geron2017supervisedlearningConfusionMatrix}. Beispiel: Nehmen wir an, wir hätten ein Modell, dass immer die Klasse \(class_1\) vorhersagt. Die Klasse \(class_1\) besteht aus 9990 Elementen und von den anderen Klassen \(class_2\) bis \(class_n\) haben wir genau 10. Dann sieht die Confusion Matrix wie folgt aus:}
				\en{The accuracy of the entire model is a good indication of the performance of the model. However, a problem occurs in extreme cases where assumptions can no longer be made reliably. For example, if you are working with an unbalanced dataset\autocite{geron2017supervisedlearningConfusionMatrix}. Example: Suppose we have a model that always predicts the class \(class_1\). The class \(class_1\) consists of 9990 elements and of the other classes \(class_2\) to \(class_n\) we have exactly 10. Then the Confusion Matrix looks like this:}

				%\clearpage
				\begin{table}[htb]
					\centering
					{\def\arraystretch{2}\tabcolsep=5pt
						\begin{tabular}{cc|c|c|c|c|}
							\cline{3-6}
							& & \multicolumn{4}{c|}{\textbf{predicted}} \\ \cline{3-6} 
							& & \boldmath\(class_1\) & \boldmath\(class_2\) & \textbf{\ldots} & \boldmath\(class_n\) \\ \hline
							\multicolumn{1}{|l|}{\multirow{4}{*}{\rotatebox{90}{\textbf{actual}}}} & \boldmath\(class_1\) & \(TP = 9990\)                  & \multicolumn{3}{c|}{\(FN = 0\)} \\ \cline{2-6} 
							\multicolumn{1}{|c|}{} & \boldmath\(class_2\) & \multirow{3}{*}{\(FP = 10\)} & \multicolumn{3}{c|}{\multirow{3}{*}{\(TN = 0\)}} \\ \cline{2-2}
							\multicolumn{1}{|c|}{} & \textbf{\ldots} & & \multicolumn{3}{c|}{}                   \\ \cline{2-2}
							\multicolumn{1}{|c|}{} & \boldmath\(class_n\) & & \multicolumn{3}{c|}{}                   \\ \hline
						\end{tabular}
					}
					\captionof{table}{Confusion matrix}\label{tbl:table_confusion_matrix}
				\end{table}

				\de{Die Modell-Genauigkeit ist ein ist in diesem Fall 99,9\%, obwohl es ein schlechtes Modell ist:}
				\en{The model accuracy in this case is 99.9\%, although it is a bad model:}

				\begin{equation}
					Accuracy = 99,9\%
				\end{equation}

				\de{Deswegen gibt es weitere Performance Metriken wie Precision, Recall und F-Measure.}
				\en{Therefore there are additional performance metrics like Precision, Recall and F-Measure.}

			% -------------------- %
			% Precision %
			% -------------------- %
			\paragraph{Precision}
				\de{Precision\footnote{``Precision and recall'', Wikipedia contributors, February 7, 2020, \url{https://en.wikipedia.org/wiki/Precision_and_recall}} sagt aus, wie zuverlässig die Aussage einer Vorhersage einer Klasse ist:}
				\en{Precision\footnote{``Precision and recall'', Wikipedia contributors, February 7, 2020, \url{https://en.wikipedia.org/wiki/Precision_and_recall}} expresses how reliable the statement of a prediction of a class is:}

				\begin{equation}
					Precision = {{Correct} \over {Actual}} = {{TP} \over {TP + FP}}
				\end{equation}

				\de{Oder genauer für die Klasse c:}
				\en{Or more precisely for class c:}

				\begin{equation}
					Precision_{@c} = {{a_{cc}} \over {\sum_{i=1}^{n} a_{ic}}}
				\end{equation}

			% -------------------- %
			% Recall %
			% -------------------- %
			\paragraph{Recall}
				\de{Recall\footnote{``Precision and recall'', Wikipedia contributors, February 7, 2020, \url{https://en.wikipedia.org/wiki/Precision_and_recall}} ist die Genauigkeit einer Klasse. Das bedeutet wie gut konnte die Klasse vorhergesehen werden:}
				\en{Recall\footnote{``Precision and recall'', Wikipedia contributors, February 7, 2020, \url{https://en.wikipedia.org/wiki/Precision_and_recall}} is the accuracy of a class. This means how well the class could be predicted:}

				\begin{equation}
					Recall = {{Correct} \over {CorrectPossible}} = {{TP} \over {TP + FN}}
				\end{equation}

				\de{Oder genauer für die Klasse c:}
				\en{Or more precisely for class c:}

				\begin{equation}
					Recall_{@c} = {{a_{cc}} \over {\sum_{i=1}^{n} a_{ci}}}
				\end{equation}

			% -------------------- %
			% F-Measure %
			% -------------------- %
			\paragraph{F-Measure}
				\de{F-Measure\footnote{``F1 score'', Wikipedia contributors, February 7, 2020, \url{https://en.wikipedia.org/wiki/F1_score}} kombiniert Präzision und Rückruf, wobei der Parameter \(\beta\) die Gewichtung darstellt:}
				\en{F-Measure\footnote{``F1 score'', Wikipedia contributors, February 7, 2020, \url{https://en.wikipedia.org/wiki/F1_score}} combines precision and recall, with the parameter \(\beta\) representing the weighting:}
				\begin{equation}
					F_\beta =
					(1 + \beta^2) \cdot {{Precision\cdot Recall}\over{\beta^2 \cdot Precision + Recall}} = 
					{{(1 + \beta^2) \cdot TP}\over{(1 + \beta^2) \cdot TP + \beta^2 \cdot FN + FP}}
				\end{equation}

				\de{Je höher der \(\beta\), desto mehr Wert wird auf Precision statt auf Recall gelegt. Das ist wichtig, wenn man mehr Wert auf die Qualität der Verhersage legt, als auf die Erkennungsgenauigkeit. Z.B. bei einer Vorhersage von Krankheiten: Zuordnung von Klasse Krank bei gesunde Menschen ist hier genauso fatal wie auch die Zuordnung von Klasse Gesund bei kranken Menschen (Obwohl Fall zwei fataler wäre als Fall eins). Mit einem Wert von \(\beta = 0,5\) erhalten wir eine Gleichverteilung beider Werte und wird F1 score genannt:}
				\en{The higher \(\beta\) the more importance is placed on precision instead of recall. This is important if you put more importance on the quality of the prediction than on the accuracy of prediction. For example, when predicting diseases: assigning class ``ill'' to healthy people is just as fatal as assigning class ``healthy'' to sick people (although case two would be even more fatal than case one). With a beta value of \(\beta = 0,5\) we get an equal distribution of both values and is called F1 score:}

				\begin{equation}
					F_1 =
					{{2 \cdot Precision \cdot Recall}\over{Precision + Recall}} = 
					{{2 \cdot TP}\over{2 \cdot TP + FN + FP}}
				\end{equation}

			% -------------------- %
			% loss function %
			% -------------------- %
			\paragraph{Loss function}
				\de{Da es sich hierbei um ein Klassifzierungsproblem und nicht um ein Regressionsproblem handelt, greift man bei der Vorhersage auf die Softmax-Regression zurück. Dabei wird nach jeder Vorhersage ein Vektor \(\lambda\) der Größe \(n\) zurückgegeben, wobei \(n\) der Anzahl der zu unterscheidenden Klassen entspricht\autocite{geron2017supervisedlearningDecisionBoundaries}. Jeder einzelne \(\hat{p}\) Wert entspricht dabei der Wahrscheinlichkeit, dass es die Klasse \(class_n\) ist:}
				\en{Since this is a classification problem and not a regression problem, the prediction is based on softmax regression. After each prediction, a vector \(\lambda\) of the size \(n\) is returned, where \(n\) corresponds to the number of classes to be distinguished\autocite{geron2017supervisedlearningDecisionBoundaries}. Each individual \(\hat{p}\) value corresponds to the probability that it is class \(class_n\):}

				\begin{equation}
					\lambda = 
					\left(
						\begin{array}{c}
						\hat{p}_{1}\\
						\hat{p}_{2}\\
						\vdots\\
						\hat{p}_{n}\\
						\end{array}
					\right)
					\quad\Biggl\lvert \quad \sum_{i=1}^n \hat{p_i} = 1
				\end{equation}

				\de{Der erwartete Wert der Parameterfunktion und somit der aktuellen Klasse wird als One Hot Vektor zurückgegeben. Der Wert 1 entspricht der erwarteten Klasse. Alle anderen Klassen geben 0 zurück. Dies nennt man auch One Hot Encoding:}
				\en{The expected value of the parameter function and thus of the current class is returned as a one hot vector. The value 1 corresponds to the expected class. All other classes return 0. This is also called one hot encoding:}

				\begin{equation}
					g(\vartheta_2) = 
					\left(
						\begin{array}{c}
						0\\
						1\\
						\vdots\\
						0\\
						\end{array}
					\right)
				\end{equation}

				\de{Die Verlustfunktion\footnote{``Verlustfunktion (Statistik)'', Wikipedia contributors, February 7, 2020, \url{https://de.wikipedia.org/wiki/Verlustfunktion_(Statistik)}} ordnet jeder Vorhersage einen Schaden zu, der durch den Vergleich mit dem wahren Wert bzw. Parameter entsteht. Dazu wird der Abstand der vorhergesagten Klasse zur wahren Klasse berechnet (sind sie gleich ist der Abstand 0). Bessert sich mit Anpassung des Modells (Lernvorgang) die Vorhersage aller vorhergesagten Klassen zu ihren wahren Klassen, so verkleinert sich auch der Wert der Verlustfunktion. Eine typische Verlustfunktion ist z.B. für einen r-dimensionalen Raum:}
				\en{The loss function\footnote{``Verlustfunktion (Statistik)'', Wikipedia contributors, February 7, 2020, \url{https://de.wikipedia.org/wiki/Verlustfunktion_(Statistik)}} assigns a loss to each prediction, which results from the comparison with the true value or parameter. For this purpose, the distance between the predicted class and the true class is calculated (if they are equal, the distance is 0).  If the adaptation of the model (learning process) improves the prediction of all predicted classes to their true classes, the value of the loss function is also reduced.  A typical loss function is e.g. for an r-dimensional space:}

				\begin{equation}
					L_r(\vartheta, \lambda) := \lVert \lambda - g(\vartheta) \rVert^r
				\end{equation}

				\de{\(\lambda\) stellt hierbei den geschätzte Wert und \(g(\vartheta)\) die Parameterfunktion dar, welche den realen Wert für \(\vartheta\) zurückliefert. Der mittlere Verlust auf den gesamten Datensatz mit \(n\) Elementen beträgt somit:}
				\en{\(\lambda\) represents the estimated value and \(g(\vartheta)\) the parameter function which returns the actual value for \(\vartheta\). The average loss on the entire data set with \(n\) elements is thus:}

				\begin{equation}
					\hat{L} = {{1}\over{k}}\sum_{i=1}^{k} L_r(\vartheta_i, \lambda_i)
				\end{equation}

		\subsection{Machine Learning}
		\label{sec:section_machine_learning}
			\de{Maschinelles Lernen ist ein Oberbegriff für die künstliche Generierung von Wissen aus Erfahrung. Es verfolgt den Ansatz des induktiven Lernens (siehe auch Kapitel ``induktiver Ansatz''\hyperref[sec:section_inductive_approach]).}
			\en{Machine learning is a generic term for the artificial generation of knowledge from experience. It follows the approach of inductive learning (see also chapter ``inductive approach''\hyperref[sec:section_inductive_approach]).}

			\subsubsection{Artificial neural network}

				\de{Künstliche neuronale Netzwerke stellen Funktionen bereit, welche in der Lage sind hochkomplexe Daten im mehrdimensionalem Raum zu trennen. Bei großen und hochgradig komplexen Aufgaben, wie beispielsweise der Klassifizierung von Milliarden von Bildern, Sprach- und Texterkennungen, schneiden neuronale Netze meist besser ab, als andere Machine Learning Verfahren. Der erhebliche Zuwachs an Rechenkapizität seit den 1990ern ermöglicht das Trainieren großer neuronaler Netzwerke innerhalb eines sinnvollen Zeitraumes. Künstliche neuronale Netzwerke sind die Kernkomponente des Deep Learnings.}
				\en{Artificial neural networks provide functions that are able to separate highly complex data in multidimensional space. For large and highly complex tasks, such as the classification of billions of images, speech and text recognition, neural networks usually perform better than other machine learning methods. The significant increase in computational capacity since the 1990s allows the training of large neural networks within a reasonable period of time. Artificial neural networks are the core component of deep learning.}

				\de{Neuronale Netzwerke verarbeiten einen Eingabevektor und wandeln ihn in einen neuen Ausgabevektor um. Sie sind Netze aus vielen hintereinander und parallel geschalteten künstlichen Neuronen. Ein künstliches Neuron wiederrum wandelt einen Vektor in ein Skalar um, indem es die Eingänge \(\bar{x}\) mit den veränderlichen Parametern \(\bar{\omega}\) skaliert, aufsummiert und mit einem Bias \(b\) korrigiert (der Bias ist ebenso eine veränderliche Variable). Die Aktivierungsfunktion stellt sicher, dass aus dem Polynom ersten Grades (lineares Regressionsmodell) eine nichtlineare Funktion wird\footnote{``Aktivierungsfunktionen, ihre Arten und Verwendungsmöglichkeiten'', https://www.ai-united.de/, February 8, 2020, \url{https://www.ai-united.de/aktivierungsfunktionen-ihre-arten-und-verwendungsmoeglichkeiten/}}:}
				\en{Neural networks process an input vector \(\bar{x}\) and convert it into a new output vector \(\hat{\bar{x}}\). They are networks of many artificial neurons connected in series and parallel. An artificial neuron in turn converts a vector into a scalar by scaling and summing the inputs \(\bar{x}\) with the changeable parameters \(\bar{\omega}\) and correcting them with a bias \(b\) (the bias is also a changeable variable). The activation function ensures that the first degree polynomial (linear regression model) becomes a nonlinear function\footnote{``Activation functions, their types and uses'', https://www.ai-united.de/, February 8, 2020, \url{https://www.ai-united.de/aktivierungsfunktionen-ihre-arten-und-verwendungsmoeglichkeiten/}}:}

				\begin{figure}[H]
					\[
						\begin{array}{c}
							x_1\\
							x_2\\
							\color{white}\vdots\\
							x_n\\
							1\\
						\end{array}
						\begin{array}{c}
							\rightarrow\\
							\rightarrow\\
							\vdots\\
							\rightarrow\\
							\rightarrow\\
						\end{array}
						\begin{array}{c}
							\omega_1\\
							\omega_2\\
							\color{white}\vdots\\
							\omega_n\\
							b\\
						\end{array}
						\begin{array}{c}
							\diagdown\\
							\\
							\\
							\\
							\diagup\\
						\end{array}
						\circled{${\sum\atop\ }\over{\ \atop step(z)}$}
						\longrightarrow h
						\quad\Biggl\lvert \quad h = step(z) = step(\bar{\omega}^\intercal \cdot \bar{x} + b)
					\]
					\caption{The construction of an artificial neuron.}
				\end{figure}

				\de{Das künstliche neuronale Netz baut sich aus vielen hintereinandergeschalteten Layern zusammen, welche wiederrum parallel geschaltete Neuronen enthalten:}
				\en{The artificial neural network is composed of many layers connected in series, which again contain neurons connected in parallel:}

				\begin{figure}[H]
					\centering

					\tikzset{%
						every neuron/.style={
							circle,
							draw
					  	},
					  	every inputneuron/.style={
					  		circle,
					  		draw,
					  		minimum size=0.25cm
					  	},
					  	neuron 1/.style={
							circle,
							draw,
							minimum size=0.75cm,
							execute at begin node=\color{black}${\sum\atop\ }\over{\ \atop step(z)}$
					  	},
					  	neuron 2/.style={
							circle,
							draw,
							minimum size=0.75cm,
							execute at begin node=\color{black}${\sum\atop\ }\over{\ \atop step(z)}$
					  	},
					  	neuron missing/.style={
					  		draw=none,
					  		scale=2,
					  		text height=0.333cm,
					  		execute at begin node=\color{black}$\vdots$
					  	},
					  	inputneuron missing/.style={
					  		draw=none, 
					  		scale=2,
					  		text height=0.333cm,
					  		execute at begin node=\color{black}$\vdots$
						},
					}
					
					\begin{tikzpicture}[x=1.5cm, y=1.5cm, >=stealth]
						% print input neurons
						\foreach \m/\l [count=\y] in {1,2,3,missing,4}
							\node [every inputneuron/.try, inputneuron \m/.try] (input-\m) at (0,2.5-\y) {};
						
						% print hidden neurons
						\foreach \m [count=\y] in {1,missing,2}
							\node [every neuron/.try, neuron \m/.try ] (hidden-\m) at (2,2-\y*1.25) {};
						
						% print output neurons
						\foreach \m [count=\y] in {1,missing,2}
							\node [every neuron/.try, neuron \m/.try ] (output-\m) at (4,1.5-\y) {};
						
						% x_n
						\foreach \l [count=\i] in {1,2,3,n}
							\draw [<-] (input-\i) -- ++(-1,0)
								node [above, midway] {$x_\l$};
						
						% h_n
						\foreach \l [count=\i] in {1,n}
							\node [above] at (hidden-\i.north) {$h_\l$};
						
						% ^x_n
						\foreach \l [count=\i] in {1,n}
						  \draw [->] (output-\i) -- ++(1,0)
						    node [above, midway] {$\hat{x}_\l$};
						
						% lines between input and hidden layer
						\foreach \i in {1,...,4}
						  \foreach \j in {1,...,2}
						    \draw [->] (input-\i) -- (hidden-\j);
						
						% lines between hidden and output layer
						\foreach \i in {1,...,2}
						  \foreach \j in {1,...,2}
						    \draw [->] (hidden-\i) -- (output-\j);
						
						% print labels
						\foreach \l [count=\x from 0] in {Input, Hidden, Ouput}
						  \node [align=center, above] at (\x*2,2) {\l \\ layer};
					\end{tikzpicture}
					\caption{The construction of a simple neural network.}
				\end{figure}
	
				\de{Ein neuronales Netzwerk ist in der Lage komplexe Eingaben zu klassifizieren. Doch wie genau kann man sich das vorstellen? Betrachten wir eine einfache Klassifikationsfunktion, wobei \(\bar{x}\) die Koordinaten der einzelnen Klassenpunkte darstellen und \(\bar{w}\) und \(b\) lernbare Parameter sind:}
				\en{A neural network is able to classify complex inputs. But how exactly can this be imagined? Let us consider a simple classification function, where \(\bar{x}\) represent the coordinates of the individual class points and \(\bar{w}\) and \(b\) are learnable parameters:}
	
				\begin{equation}
					f(\bar{x}, \bar{\omega}, b) = sgn(\bar{\omega}^\intercal \cdot \bar{x} + b)
				\end{equation}

				\de{Mit dieser linearen Funktion lässt sich das nachfolgende Problem leicht klassifizieren:}
				\en{With this linear function the following problem can be easily classified:}

				\begin{figure}[H]
					\begin{center}
						\scalebox{0.5}{\input{images/pgf/linear_classifier.pgf}}
					\end{center}
					\caption{Simple class shattering}
					\label{fig:evaluation_simple_class_shattering}
				\end{figure}
	
				\de{Die Funktion entspricht einem neuronalen Netz ohne verdeckte Schicht und enthält nur eine Eingangs- und eine Ausgangsschicht mit einem künstlichem Neuron ohne Aktivierungsfunktion. Die Dimension, die diese Funktion trennen kann, ist 2 und wird als VC-Dimension\footnote{Vapnik–Chervonenkis dimension: \url{https://en.wikipedia.org/wiki/Convolutional_neural_network}}. Diese Funktion kann genau 2 Klassen trennen. Aber was ist mit nichtlinearen Problemen? In diesem Fall schauen wir uns die folgenden Klassifikationen an:}
				\en{The function corresponds to a neural network without a hidden layer and contains only one input and one output layer with one artificial neuron without activation function. The dimension that this function can separate is 2 and is called VC dimension\footnote{Vapnik–Chervonenkis dimension: \url{https://en.wikipedia.org/wiki/Convolutional_neural_network}}. This function can separate exactly 2 classes. But what about nonlinear problems? In this case let's look at the following classifications:}
				
				\begin{figure}[H]
					\begin{center}
						\scalebox{1.0}{\includetex{classification}}
					\end{center}
					\caption{Linear vs. nonlinear classification}
					\label{fig:overview_linear_nonlinear_classification}
				\end{figure}
	
				\de{Für das zweite Problem können wir die Funktion noch anpassen. Für das dritte nichtlineare Problem ist der Klassifikationsraum nicht mehr ausreichend und erfordert einen anderen Algorithmus. Und hier kommen die neuronalen Netze ins Spiel. Ein Tool, um das Trennen von Daten zu visualisieren und die Funktionsweise der einzelnen Layer zu testen ist \url{https://playground.tensorflow.org}\footnote{Neural Network Right Here in Your Browser: \url{https://playground.tensorflow.org}}. Ein nichtlineares Problem kann im einfachsten Fall schon mit einer hinzugefügten versteckten Schicht mit drei weiteren Neuronen gelöst werden:}
				\en{For the second problem we can still adjust the function. For the third nonlinear problem the classification space is no longer sufficient and requires a different algorithm. And this is where the neural networks come into play. A tool to visualize the separation of data and to test the functionality of the individual layers is \url{https://playground.tensorflow.org}\footnote{Neural Network Right Here in Your Browser: \url{https://playground.tensorflow.org}}. In the simplest case, a nonlinear problem can be solved by adding a hidden layer with three additional neurons:}

				\begin{figure}[H]
					\centering
					\includegraphics[width=1.0\textwidth]{images/simple_neuronal_network}
					\caption[Simple neuronal network with one hidden layer]{Simple neuronal network with one hidden layer\footnotemark}
					\label{fig:beispiel4}
				\end{figure}
				\footnotetext{Source: \url{http://playground.tensorflow.org/}}
		
			\subsubsection{Convolutional Neuronal Network}
				\de{Ein neuronales Netzwerk verarbeitet einen Vektor und gibt einen neuen Vektor zurück. Das Problem bei Eingabedaten wie Bildern ist, dass sie auf den ersten Blick nicht erfolgreich als Vektor beschrieben werden können, um mit einem normalem neuronalem Netzwerk trainiert werden zu können. Man braucht einen Algorithmus, welcher auch matrizenähnliche Eingaben verarbeiten kann und in der Lage ist Muster zu erkennen. Dabei wurde in der Vergangenheit das Prinzip der Convolutional Layer entwickelt. Ein Convolutional Layer nimmt ein Matrix Eingang entgegen, transformiert diese und gibt wie auch bei den künstlichen Neuronen einen Ausgangswert zurück (in diesem Fall eine weitere Matrix). Dieser Ausgangswert wird danach an die nächste Schicht weitergegeben. Dabei beinhaltet ein Convolutional Layer eine Menge \(n\) an quadratischen Matrizen (meist 3x3 oder 5x5 Matrizen). Diese Matrizen werden Filter genannt. Jeder Filter\footnote{Filter, welche z.B. Kanten, Ecken, Quadrate, etc. erkennen können und in tieferen Layern Dinge wie Augen, Ohren, Haare, etc.} wird nun jeweils von links oben bis rechts unten über die Pixel des Bildes mittels Skalarprodukt miteinander verrechnet, wobei ein neues Bild entsteht. Die soganannte Feature Map. Bei einer Anzahl von \(n\) Filtern entstehen am Ende \(n\) Feature Maps und heben die in den Filtern definierten Merkmale jeweils im neu errechneten Bild hervor. Dieser Vorgang wird auch Faltung genannt\autocite{deeplizard2017CNNExplained}.}
				\en{A neural network processes a vector and returns a new vector. The problem with input data such as images is that at first view they cannot be successfully described as vectors to be trained with a normal neural network. You need an algorithm that can handle matrix-like inputs and that is able to recognize patterns. In the past the principle of the convolutional layer was developed. A convolutional layer receives a matrix input, transforms it and returns an output value (in this case another matrix). This output value is then passed on to the next layer. A convolutional layer contains a set \(n\) of square matrices (usually 3x3 or 5x5 matrices). These matrices are called filters. Each filter\footnote{Filters, which can recognize edges, corners, squares, etc. and in deeper layers things like eyes, ears, hair, etc.} is now calculated from top left to bottom right over the pixels of the image using a scalar product, which creates a new image. The so-called Feature Map. With a number of \(n\) filters, \(n\) feature maps are created at the end and highlight the features defined in the filters in the newly calculated image. This process is also called convolution\autocite{deeplizard2017CNNExplained}.}

				\de{Neuronale Netze, welche Gebrauch von Convolutional Layern machen, werden Convolutional Neuronal Networks genannt (kurz CNN) und haben einen entscheidenden Beitrag zum Fortschritt der Bildklassifizierung und auch in anderen Bereichen wie Spracherkennung geleistet. Neben den Convolutional Layern existieren in einem Convolutional Neuronal Network weitere spezielle Layer, welche sich von normalen Neuronalen Netzen unterscheiden: Z.B. die Pooling Layer. In einem Pooling Layer werden überflüssige Informationen verworfen und die Featuremaps verkleinert. Dieser Vorgang verringert den Speicherbedarf und erhöht Berechnungsgeschwindigkeit. Die Convolutional Layer und die Pooling Layer wechseln sich in aller Regel jeweils ab, bis am Ende statt einer \(n x n\) Matrix des Eingangsbildes ein großer Vektor entsteht, welcher von einem normalen neuronalem Netzwerk weiterverarbeitet werden kann und schlußendlich in dem schon beschriebenen One Hot Vektor endet.}
				\en{Neural networks that make use of convolutional layers are called convolutional neural networks (in short CNN) and have made a decisive contribution to the progress of image classification and also in other areas like speech recognition. In addition to the Convolutional Layers, a Convolutional Neural Network has other special layers that differ from normal neural networks: For example the Pooling Layer. In a pooling layer, unnecessary information is discarded and feature maps are reduced in size. This process reduces memory requirements and increases calculation speed. The convolutional layer and the pooling layer usually alternate until a large vector is created at the end instead of a \(n x n\) matrix of the input image, which can be further processed by a normal neural network and finally ends in the already described one hot vector.}

				\begin{figure}[H]
					\centering
					\begin{tikzpicture}
						\tikzmath{
							\inputImageWidth = 1.0;
							\layerOneDistance = 0.22;
							\layerOnePosition = 1.95;
							\layerOneWidth = 1.0;
							\layerTwoDistance = 0.12;
							\layerTwoPosition = 4.40;
							\layerTwoWidth = 0.6;
							\layerThreeDistance = 0.12;
							\layerThreePosition = 6.50;
							\layerThreeWidth = 0.6;
							\layerFourDistance = 0.052;
							\layerFourPosition = 8.5;
							\layerFourWidth = 0.36;
						}

						% input image
						\node at (0.5,-1){\begin{tabular}{c}input image\end{tabular}};
						\draw
							(0 * \inputImageWidth, 0 * \inputImageWidth) --
							(1 * \inputImageWidth, 0 * \inputImageWidth) --
							(1 * \inputImageWidth, 1 * \inputImageWidth) --
							(0 * \inputImageWidth, 1 * \inputImageWidth) --
							(0 * \inputImageWidth, 0 * \inputImageWidth);
						
						% layer 1
						\node at (3.0, 3.0){\begin{tabular}{c}convolutional layer\\layer $l = 1$\end{tabular}};
						\foreach \i in {0,...,5}
							\draw[fill=black, opacity=0.2, draw=black]
								(\layerOnePosition + 0 * \layerOneWidth + \layerOneDistance*\i, 0 * \layerOneWidth + \layerOneDistance*\i) --
								(\layerOnePosition + 1 * \layerOneWidth + \layerOneDistance*\i, 0 * \layerOneWidth + \layerOneDistance*\i) --
								(\layerOnePosition + 1 * \layerOneWidth + \layerOneDistance*\i, 1 * \layerOneWidth + \layerOneDistance*\i) --
								(\layerOnePosition + 0 * \layerOneWidth + \layerOneDistance*\i, 1 * \layerOneWidth + \layerOneDistance*\i) --
								(\layerOnePosition + 0 * \layerOneWidth + \layerOneDistance*\i, 0 * \layerOneWidth + \layerOneDistance*\i);

						% layer 2
						\node at (5.0,-1){\begin{tabular}{c}pooling layer\\layer $l = 2$\end{tabular}};
						\foreach \i in {0,...,5}
							\draw[fill=black, opacity=0.2, draw=black]
								(\layerTwoPosition + 0 * \layerTwoWidth + \layerTwoDistance*\i, 0 * \layerTwoWidth + \layerTwoDistance*\i) --
								(\layerTwoPosition + 1 * \layerTwoWidth + \layerTwoDistance*\i, 0 * \layerTwoWidth + \layerTwoDistance*\i) --
								(\layerTwoPosition + 1 * \layerTwoWidth + \layerTwoDistance*\i, 1 * \layerTwoWidth + \layerTwoDistance*\i) --
								(\layerTwoPosition + 0 * \layerTwoWidth + \layerTwoDistance*\i, 1 * \layerTwoWidth + \layerTwoDistance*\i) --
								(\layerTwoPosition + 0 * \layerTwoWidth + \layerTwoDistance*\i, 0 * \layerTwoWidth + \layerTwoDistance*\i);
						
						%layer 3
						\node at (7.5,3.0){\begin{tabular}{c}convolutional layer\\layer $l = 3$\end{tabular}};
						\foreach \i in {0,...,11}
							\draw[fill=black, opacity=0.2, draw=black]
								(\layerThreePosition + 0 * \layerThreeWidth + \layerThreeDistance*\i, 0 * \layerThreeWidth + \layerThreeDistance*\i) --
								(\layerThreePosition + 1 * \layerThreeWidth + \layerThreeDistance*\i, 0 * \layerThreeWidth + \layerThreeDistance*\i) --
								(\layerThreePosition + 1 * \layerThreeWidth + \layerThreeDistance*\i, 1 * \layerThreeWidth + \layerThreeDistance*\i) --
								(\layerThreePosition + 0 * \layerThreeWidth + \layerThreeDistance*\i, 1 * \layerThreeWidth + \layerThreeDistance*\i) --
								(\layerThreePosition + 0 * \layerThreeWidth + \layerThreeDistance*\i, 0 * \layerThreeWidth + \layerThreeDistance*\i);
						
						% layer 4
						\node at (9.0,-1){\begin{tabular}{c}pooling layer\\layer $l = 4$\end{tabular}};
						\foreach \i in {0,...,11}
							\draw[fill=black, opacity=0.2, draw=black]
								(\layerFourPosition + 0 * \layerFourWidth + \layerFourDistance*\i, 0 * \layerFourWidth + \layerFourDistance*\i) --
								(\layerFourPosition + 1 * \layerFourWidth + \layerFourDistance*\i, 0 * \layerFourWidth + \layerFourDistance*\i) --
								(\layerFourPosition + 1 * \layerFourWidth + \layerFourDistance*\i, 1 * \layerFourWidth + \layerFourDistance*\i) --
								(\layerFourPosition + 0 * \layerFourWidth + \layerFourDistance*\i, 1 * \layerFourWidth + \layerFourDistance*\i) --
								(\layerFourPosition + 0 * \layerFourWidth + \layerFourDistance*\i, 0 * \layerFourWidth + \layerFourDistance*\i);
						
						% layer 5
						\node at (12,3.0){\begin{tabular}{c}fully connected layer\\layer $l = 5$\end{tabular}};
						\draw[fill=black,draw=black,opacity=0.5]
							(10.5,0) --
							(11,0) --
							(12.75,1.75) --
							(12.25,1.75) --
							(10.5,0);
						
						% layer 6
						\node at (13,-1){\begin{tabular}{c}fully connected layer\\output layer $l = 6$\end{tabular}};
						\draw[fill=black,draw=black,opacity=0.5]
							(12.5,0.5) --
							(13,0.5) --
							(13.65,1.15) --
							(13.15,1.15) --
							(12.5,0.5);
					\end{tikzpicture}
					\caption[Architecture of a traditional convolutional neural network.]{Architecture of a traditional convolutional neural network.}
					\label{fig:traditional-convolutional-network}
				\end{figure}

				\de{Ein großer Vorteil von Convolutional neuronal networks soll nicht unerwähnt bleiben: Sie benötigen relativ wenig Vorverarbeitung im Vergleich zu anderen Bildklassifikationsalgorithmen. Dies bedeutet, dass das Netzwerk eigenständig die Filter lernt, die in herkömmlichen Algorithmen normalerweise von Hand entwickelt werden, wenn es mit ausreichender Schulung trainiert wird. Diese Eigenschaft dieser Netzwerke ist von großem Vorteil, da sie automatisiert durchgeführt werden können und sich bei Änderungen der Eingabedaten selbstständig ändern und keinem menschlichem Eingriff bedarf.}
				\en{A big advantage of convolutional neural networks should not remain unmentioned: They require relatively little preprocessing compared to other image classification algorithms. This means that the network independently learns the filters that are normally developed by hand in conventional algorithms, if trained with adequate training. This property of these networks is a great advantage because they can be automated and change independently when the input data changes and do not require human intervention.}
	
			\subsubsection{Transfer Learning}
				\de{Convolutional neuronal networks sind großartig und haben einen entscheidenden Beitrag zur Klassifizierung von Bilder beigetragen. Mit der Gründung der Forschungsdatenbank ImageNet im Jahre 2006 werden jährliche Wettbewerbe veranstaltet, um entwickelte Neuronale Netzwerke miteinander zu vergleichen. ImageNet ist eine Bilderdatenbank mit mehr als 14 Millionen Bildern. Ein CNN namens AlexNet im Jahr 2012 einen Top-5 Fehler von 15,3\% und erhöht sich aktuell stetig jedes Jahr. Aber die Architektur von einem CNN hat ein Problem. Alle Convolutional Layer sind vom Beginn an zufällig initialisiert und enthalten noch keine Muster. Damit sie zuverlässig funktioniert, muss sie mit vielen Bildern trainiert werden. Würde man vom Scratch an ein CNN selbst entwickeln und verwenden, so müssen alle Convolutional Layer auch vorab trainiert werden.}
				\en{Convolutional neural networks are great and have made a significant contribution to the classification of images. With the foundation of the research database ImageNet in 2006, annual competitions are organized to compare developed neural networks. ImageNet is an image database with more than 14 million images. A CNN called AlexNet in 2012 got a top-5 error of 15.3\% and is currently increasing steadily every year. But the architecture of a CNN has a problem. All convolutional layers are randomly initialized from the beginning and do not yet contain any patterns. For it to work reliably, it needs to be trained with many images. If one would develop and use a CNN from scratch, all convolutional layers have to be trained in advance.}

				\de{Die Convolutional Layer extrahieren Features wie Kanten, Quadrate, Kreise, etc. Diese sind so gut wie in jedem Bild vorhanden und es stellt sich die Frage, ob man diese nicht wiederverwenden kann, um den Trainingsaufwand zu verringern. Die Idee beim Transfer Learning ist es ein schon vortrainiertes CNN zu verwenden und lediglich das neuronale Netzwerk am Ende des Convolutional neuronal networks an die eigene Problemstellung anzupassen.}
				\en{The convolutional layers extract features such as edges, squares, circles, etc. These are present in almost every image and the question arises whether you can reuse them to reduce the training effort. The idea of Transfer Learning is to use an already pre-trained CNN and just adapt the neural network at the end of the Convolutional neural network to the own problem.}

				\hl{Put a picture in here.}

				\de{Welchen Vorteil ein vortrainiertes Netzwerk hat, kann man in dieser Arbeit im Kapitel ``\nameref{sec:section_use_of_the_transfer_learning_approach}" einsehen.}
				\en{The advantage of a pre-trained network can be seen in the chapter ``\nameref{sec:section_use_of_the_transfer_learning_approach}" of this thesis.}
			
			\subsubsection{Overview of current and known convolutional neural networks}
				\de{Zu guter Letzt folgen hier noch ein paar aktuelle und bekannte Convolutional Neuronal networks. Sie unterscheiden sich hauptsächlich in folgenden Metriken, wobei in Kombination jedes Netzwerk seine Vor- und Nachteile besitzt:}
				\en{Last but not least, here are a few current and well-known convolutional neural networks. They differ mainly in the following metrics, whereby in combination each network has its advantages and disadvantages:}

				\begin{itemize}
					\item the top-1 accuracy (based on the ImageNet image dataset)
					\item the computing operations which are required for a single forward pass (G-Ops)
					\item the model size (for comparison: the model size of InceptionV3 is about 180 MB)
				\end{itemize}
		
				\begin{figure}[H]
					\centering
					\includegraphics[width=1.0\textwidth]{images/tl_models}
					\caption[Overview of current and known convolutional neural networks.]{Overview of current and known convolutional neural networks.\footnotemark}
					\label{fig:beispiel5}
				\end{figure}
				\footnotetext{Source: \url{https://towardsdatascience.com/neural-network-architectures-156e5bad51ba}}
					
					
					
	% -------------------- %
	% Insufficient amount of data %
	% -------------------- %
	\section{Insufficient amount of data}
	\label{sec:section_insufficient_amount_of_data}
		\de{Gibt man einem Menschen einen Donut und erkärt ihm, dass es ein Donut ist, so ist dieser nach einigem Wiederholen selbstständig in der Lage diesen Donut in der Zukunft zu klassifizieren. Bei Machine Learning ist diese Problematik etwas komplexer. Wie bei den meisten machinellen Lernverfahren benötigt man eine große Menge an Daten. Wieviel ist nicht richtig belegt. Gerade wenn man es mit vielen vorherzusagenden Klassen zu tun hat, erhöht sich die Datenmenge erfahrungsgemäß. Einige Meinungen in Foren und Blogartikeln besagen (Hypothese), dass es mindestens 1000 Bilder pro Klasse sein müssen.\footnote{``Deep Learning for Image Classification with Less Data'', https://towardsdatascience.com, February 2, 2020, \url{https://towardsdatascience.com/deep-learning-for-image-classification-with-less-data-90e5df0a7b8e}}\textsuperscript{,}\footnote{``How many images do you need to train a neural network?'', https://petewarden.com, February 2, 2020, \url{https://petewarden.com/2017/12/14/how-many-images-do-you-need-to-train-a-neural-network/}}\textsuperscript{,}\footnote{``What is the minimum sample size required to train a Deep Learning model - CNN?'', https://www.researchgate.net, February 2, 2020, \url{https://www.researchgate.net/post/What_is_the_minimum_sample_size_required_to_train_a_Deep_Learning_model-CNN}}\textsuperscript{,}\autocite{krizhevsky2012imagenet}.}
		\en{If you give a person a donut and explain to him that it is a donut, then after some repetition he is able to classify this donut in the future. With Machine Learning this problem is a bit more complex. As with most machine learning methods, a large amount of data is required. How much is not properly documented. Especially when you are dealing with many classes to be predicted, experience shows that the amount of data increases. Some opinions in forums and blog articles say (hypothesis) that there must be at least 1000 pictures per class.\footnote{``Deep Learning for Image Classification with Less Data'', https://towardsdatascience.com, February 2, 2020, \url{https://towardsdatascience.com/deep-learning-for-image-classification-with-less-data-90e5df0a7b8e}}\textsuperscript{,}\footnote{``How many images do you need to train a neural network?'', https://petewarden.com, February 2, 2020, \url{https://petewarden.com/2017/12/14/how-many-images-do-you-need-to-train-a-neural-network/}}\textsuperscript{,}\footnote{``What is the minimum sample size required to train a Deep Learning model - CNN?'', https://www.researchgate.net, February 2, 2020, \url{https://www.researchgate.net/post/What_is_the_minimum_sample_size_required_to_train_a_Deep_Learning_model-CNN}}\textsuperscript{,}\autocite{krizhevsky2012imagenet}}

		\de{Je nach Anzahl von zu trainierenden Klassen gelangt man somit schnell zu einem benötigten Datenset, welches aus mehrere Gigabyte an Daten besteht. Mittels Transfer Learning ist es möglich diese Zahl nochmals etwas zu reduzieren, jedoch bleibt das Problem der vielen Daten bestehen. Ein Paper von Microsoft aus dem Jahre 2001 zeigte zur damaligen Zeit, dass einfache Algorithmen mit genügend Daten ähnliche Ergebnisse lieferten, wie komplexe Algorithmen auf Basis weniger Daten. Dabei bezogen sich die Forscher auf Daten, welche Sprachkonstrukte klassifizieren sollten:}
		\en{Depending on the number of classes to be trained, you will quickly arrive at the required data set, which consists of several gigabytes of data. With Transfer Learning it is possible to reduce this number a little bit, but the problem of the large amount of data remains. A paper  from Microsoft in 2001 showed at that time that simple algorithms with enough data gave similar results as complex algorithms based on less data. The researchers referred to data which should classify language constructs:}
		
		\blockquote{\textit{We have shown that for a prototypical natural language classification task, the performance of learners can benefit significantly from much larger training sets.}}\autocite{banko2001scaling}
		
		\de{In einem anderen Artikel nur wenige Jahre später wird dieses Thema ebenfalls aufgegriffen. Dabei bezog man sich auf Daten, welche von Texten lernen und man meist nur kleine oder mittelgroße Datensätze zur Verfügung hat. Um die Effizienz auch in diesem Fall zu verbessern, ist es eine gute Idee die Algorithmen und Methoden zu verbessern: \hl{Beispiele!}}
		\en{Another article only a few years later also addresses this issue. This referred to data that learn from texts and that usually only small or medium sized data sets are available. To improve the efficiency also in this case, it is a good idea to improve the algorithms and methods: \hl{Examples!}}

		\blockquote{\textit{...\autocite{halevy2009unreasonable}.}}



	% -------------------- %
	% Validation process %
	% -------------------- %
	\section{Related work}
		\hl{...}



	% -------------------- %
	% Validation process %
	% -------------------- %
	\section{Validation process}

		\hl{This is the part where I explain my approach.}
	
		\subsection{Preamble}
			In the following, the best possible accuracy is to be achieved by testing various parameters.
			A learning set with the following properties was used:
	
			\begin{itemize}
				\item 14865 images
				\item classified within 50 classes
				\item different number of images per class (unbalanced)
			\end{itemize}
	
			With the exception of the model tests, all tests were based on the following parameters
			(whereby one value of the parameters varied depending on the chapter):
		
			\begin{itemize}
				\item model: resnet18
				\item learning rate: 0,001 (decreases every 7 epochs to 10\% of the previous value)
				\item batch size: 48
				\item epochs: 21 (learning rate from epoch 15 to 21: 0,00001)
				\item image size: 224x224 pixels
				\item the entire training and validation set (14865 images)
			\end{itemize}
		
			Different models were tried out in chapter \flqq\nameref{usedModels}\footnote{
				see on page \pageref{usedModels}
				chapter \ref{usedModels}
				\flqq\nameref{usedModels}\frqq
			}\frqq{} with the same
			parameters as above:
		
			\begin{itemize}
				\item ResNet18
				\item ResNet50
				\item ResNet152
				\item AlexNet
				\item VGG
				\item SqueezeNet
				\item DenseNet
				\item Inception v3
			\end{itemize}
			
		\subsection{Working environment}
	
			\hl{Explain in this part of the thesis the frameworks, environments and hardware used, etc.}
			
		\subsection{Splitting and preparing the data}
		
			\subsubsection{Situation}
			
				We have 14866 images differently distributed in 50 classes (unbalanced). We would like to divide these into 80\% training and 20\% validation images.
				
			\subsubsection{Unbalanced}
			
				The unbalanced dispersion data set is divided exactly in the same ratio:
				
				\begin{itemize}
					\item 2953 images for the training
					\item 11913 images for validation
				\end{itemize}
				
				For training with different training elements, the validation dataset of 2953 images is retained for a comparable result. The number of training elements deviating from the total data set results from this:
				
				\begin{equation}
					n_{train} = k \cdot 500;  k \in 1 \dots 26
				\end{equation}
			
			\subsubsection{Balanced}
		
				\noindent ...
	
		\subsection{Performance}
		
			\noindent ...
		
		\pagebreak
	
		\subsection{Accuracy and evaluations}

			\noindent ...

			\subsubsection{Influence of number of trained images on accuracy}
	
				\noindent ...

				\begin{figure}[H]
					\begin{center}
						\input{images/evaluation/number_train_files.pgf}
					\end{center}
					\caption{Overview of influence of number of trained images on accuracy}
					\label{fig:evaluation_number_train_files}
				\end{figure}

				\noindent ...
		
			\subsubsection{Comparison of different CNN models}

				\noindent ...

				\begin{figure}[H]
					\begin{center}
						\input{images/evaluation/different_models.pgf}
					\end{center}
					\caption{Overview of known transfer learning models}
					\label{fig:evaluation_different_models}
				\end{figure}

				\noindent ...
		
			\subsubsection{Use of the transfer learning approach}
			\label{sec:section_use_of_the_transfer_learning_approach}
	
				\noindent ...

				\begin{figure}[H]
					\begin{center}
						\input{images/evaluation/transfer_learning.pgf}
					\end{center}
					\caption{Overview of use of the transfer learning approach}
					\label{fig:evaluation_transfer_learning}
				\end{figure}

				\noindent ...

			\subsubsection{Influence of different error optimizers}

				\paragraph{Comparison Optimizer}

				\noindent ...

				\begin{figure}[H]
					\begin{center}
						\input{images/evaluation/best_optimizer.pgf}
					\end{center}
					\caption{Overview of best optimizer}
					\label{fig:evaluation_momentum}
				\end{figure}

				\noindent ...

				\paragraph{Influence of the momentum and the Nesterov momentum}

				\noindent ...

				\begin{figure}[H]
					\begin{center}
						\inputpgf{images/evaluation}{momentum.pgf}
					\end{center}
					\caption{Overview momentum vs nesterov momentum}
					\label{fig:evaluation_momentum}
				\end{figure}

				\noindent ...
		
			\subsubsection{Influence of the number of trained layers on the accuracy}
	
				\noindent ...

				\begin{figure}[H]
					\begin{center}
						\inputpgf{images/evaluation}{number_trainable_layers.pgf}
					\end{center}
					\caption{Overview of influence of the number of trained layers}
					\label{fig:evaluation_number_trainable_layers}
				\end{figure}

				\noindent ...
		
			\subsubsection{Influence of a dynamic learning rate on accuracy (scheduling)}

				\noindent ...

				\begin{figure}[H]
					\begin{center}
						\inputpgf{images/evaluation}{scheduling_learning_rate.pgf}
					\end{center}
					\caption{Overview of a dynamic learning rate on accuracy}
					\label{fig:evaluation_scheduling_learning_rate}
				\end{figure}

				\noindent ...
		
			\subsubsection{Different batch sizes}
	
				\noindent ...
		
			\subsubsection{Different image sizes}
	
				\noindent ...
		
			\subsubsection{Different number of learned epochs}
	
				\noindent ...


	
	% -------------------- %
	% Optimization process %
	% -------------------- %
	\section{Optimization process}
		This chapter contains ideas, approaches and evaluations of more complex ideas, which do not fit into the range of simple parameter changes.
	
		\subsection{Preamble}
			\noindent ...

		\subsection{Data augmentation}
			\noindent ...

			\begin{figure}[H]
				\begin{center}
					\inputpgf{images/pgf}{augment.pgf}
				\end{center}
				\caption{Data Augmentation}
				\label{fig:data_augmentation}
			\end{figure}

		\subsection{Enrichment of the data set from other data sources}
			\noindent ...
		
		\subsection{Analyses with multidimensional scaling}
			\noindent ...
		
		\subsection{Hierarchical classification}
			\de{Durch die Verwendung eines einzigen Modelles für alle Klassen, sind die bisherigen Klassifikatoren darauf trainiert, den Verlust am Klassenausgabevektor zu minimieren. Jede bisher verwendete Klasse hat den gleichen Rang sowohl beim Training, als auch bei der Klassifizierung. Die Vorhersage von "Pizza" kostet genauso viel wie die Vorhersage von "Martini".}
			\en{By using a single model for all classes, previous classifiers have been trained to minimize the loss of the class output vector. Each class used so far has the same rank in both training and classification. The prediction of "Pizza" costs the same as the prediction of "Martini".}

			\de{Die menschliche Fähigkeit Objekte einordnen zu können, funktioniert nicht nur auf einer Ebene. Kategorien werden sich natürlich überlappen und eine hierarchische Struktur aufweisen. So wird ein Mensch ein Bild beispielsweise unter "Pizza", "Thunfischpizza" oder sogar "Fastfood" einordnen, was so gesehen korrekt ist. Je nach Einordnung findet hier lediglich ein "Informationsverlust" statt. Jedoch wird der Mensch eine "Pizza" meist nicht fälschlicherweise als "Martini" verwechseln, welcher eher der Kategorie "Getränk" oder "Cocktail" einzuordnen ist\autocite{rosch2004basic}.}
			\en{The human ability to classify objects does not only work on one level. Categories will naturally overlap and have a hierarchical structure. For example, a human will classify a picture under "pizza", "tuna pizza" or even "fast food", which is correct from this point of view. Depending on the classification, there will only be a "loss of information". However, a person will not mistake a "pizza" as a "Martini", which is more likely to be classified as a "drink" or "cocktail"\autocite{rosch2004basic}.}
		
		\subsection{Binary classifiers}
			\noindent ...
		
		\subsection{Evaluation}
			\noindent ...
		
		\subsection{Use of the model across programming languages}
			\noindent ...



	% -------------------- %
	% Summary and outlook %
	% -------------------- %
	\pagebreak
	\section{Summary and outlook}
		\hl{What's the outcome? What else is possible? How can this work be continued? In here!}


	% -------------------- %
	% List of figures %
	% -------------------- %
	\pagebreak
	\renewcommand{\listfigurename}{List of figures}
	\addcontentsline{toc}{section}{List of figures}
	\listoffigures
	\listoftables
	


	% -------------------- %
	% List of literature %
	% -------------------- %
	\pagebreak	
	\section*{List of literature}
		\addcontentsline{toc}{section}{List of literature}
		\printbibliography[heading=none]
	


	% -------------------- %
	% List of literature %
	% -------------------- %
	\pagebreak	
	\section*{List of links}
		\addcontentsline{toc}{section}{List of links}
		\begin{itemize}
			\item Deep learning unbalanced training data?
			\begin{itemize}
				\item \url{https://towardsdatascience.com/deep-learning-unbalanced-training-data-solve-it-like-this-6c528e9efea6}
			\end{itemize}
			\item Data Augmentation
			\begin{itemize}
				\item \url{https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/}
			\end{itemize}
			\item Stop Feeding Garbage To Your Model! — The 6 biggest mistakes with datasets and how to avoid them.
			\begin{itemize}
				\item \url{https://hackernoon.com/stop-feeding-garbage-to-your-model-the-6-biggest-mistakes-with-datasets-and-how-to-avoid-them-3cb7532ad3b7}
			\end{itemize}
		\end{itemize}
	


	% -------------------- %
	% Declaration %
	% -------------------- %
	\pagebreak
	\section*{Declaration}
		\thispagestyle{empty}
		
		\noindent I hereby declare that the work presented in this thesis is solely my work and that to the best of my
		knowledge this work is original, except where indicated by references to other authors. No part of this
		work has been submitted for any other degree or diploma. 
		
		\begin{displaymath}
		% use packages: array
		\begin{array}{ll}
		Signature:~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
		& Place, Date:~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
		\end{array}
		\end{displaymath}

\end{document}