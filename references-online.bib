
@misc{noauthor_zotero_nodate,
	title = {Zotero {\textbar} {Connectors}},
	url = {https://www.zotero.org/download/connectors},
	urldate = {2020-02-25},
	file = {Zotero | Connectors:C\:\\Users\\bjoern\\Zotero\\storage\\RTTUKGHL\\connectors.html:text/html}
}

@misc{noauthor_most_2015,
	type = {{CT904}},
	title = {The {Most} {Popular} {Language} {For} {Machine} {Learning} {Is} ... ({IT} {Best} {Kept} {Secret} {Is} {Optimization})},
	copyright = {© Copyright IBM Corporation 2009, 2013},
	url = {www.ibm.com/developerworks/community/blogs/jfp/entry/what_language_is_best_for_machine_learning_and_data_science},
	abstract = {developerWorks wikis allow groups of people to jointly create and maintain content through contribution and collaboration. Wikis apply the wisdom of crowds to generating information for users interested in a particular subject. You can search all wikis, start a wiki,and view the wikis you own, the wikis you interact with as an editor or reader, and the wikis you follow.},
	language = {en},
	urldate = {2020-02-25},
	month = aug,
	year = {2015},
	note = {Library Catalog: www.ibm.com},
	file = {Snapshot:C\:\\Users\\bjoern\\Zotero\\storage\\USFZ8UXW\\What_Language_Is_Best_For_Machine_Learning_And_Data_Science.html:text/html}
}

@misc{sagar_deep_2019,
	title = {Deep {Learning} for {Image} {Classification} with {Less} {Data}},
	url = {https://towardsdatascience.com/deep-learning-for-image-classification-with-less-data-90e5df0a7b8e},
	abstract = {Deep Learning is indeed possible with less data},
	language = {en},
	urldate = {2020-02-25},
	journal = {Medium},
	author = {Sagar, Abhinav},
	month = nov,
	year = {2019},
	note = {Library Catalog: towardsdatascience.com},
	file = {Snapshot:C\:\\Users\\bjoern\\Zotero\\storage\\9UJP8ULV\\deep-learning-for-image-classification-with-less-data-90e5df0a7b8e.html:text/html}
}

@misc{warden_how_2017,
	title = {How many images do you need to train a neural network?},
	url = {https://petewarden.com/2017/12/14/how-many-images-do-you-need-to-train-a-neural-network/},
	abstract = {Photo by Glenn Scott Today I got an email with a question I’ve heard many times – “How many images do I need to train my classifier?”. In the early days I would reply with t…},
	language = {en},
	urldate = {2020-02-25},
	journal = {Pete Warden's blog},
	author = {Warden, Pete},
	month = dec,
	year = {2017},
	note = {Library Catalog: petewarden.com},
	file = {Snapshot:C\:\\Users\\bjoern\\Zotero\\storage\\YULDLUMR\\how-many-images-do-you-need-to-train-a-neural-network.html:text/html}
}

@misc{noauthor_what_nodate,
	title = {What is the minimum sample size required to train a {Deep} {Learning} model - {CNN}?},
	url = {https://www.researchgate.net/post/What_is_the_minimum_sample_size_required_to_train_a_Deep_Learning_model-CNN},
	abstract = {Read 23 answers by scientists with 79 recommendations from their colleagues to the question asked by Ebenezer R.H.P. Isaac on Feb 8, 2016},
	language = {en},
	urldate = {2020-02-25},
	journal = {ResearchGate},
	note = {Library Catalog: www.researchgate.net},
	file = {Snapshot:C\:\\Users\\bjoern\\Zotero\\storage\\HAX7CQWE\\What_is_the_minimum_sample_size_required_to_train_a_Deep_Learning_model-CNN.html:text/html}
}

@misc{noauthor_convolutional_2020,
	title = {Convolutional neural network},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Convolutional_neural_network&oldid=942501792},
	abstract = {In deep learning, a convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery. They are also known as shift invariant or space invariant artificial neural networks (SIANN), based on their shared-weights architecture and translation invariance characteristics. They have applications in image and video recognition, recommender systems, image classification, medical image analysis, natural language processing, and financial time series.},
	language = {en},
	urldate = {2020-02-25},
	journal = {Wikipedia},
	month = feb,
	year = {2020},
	note = {Page Version ID: 942501792},
	file = {Snapshot:C\:\\Users\\bjoern\\Zotero\\storage\\ZRNZFDKF\\index.html:text/html}
}

@article{szeliski_computer_nodate,
	title = {Computer {Vision}: {Algorithms} and {Applications}},
	language = {en},
	author = {Szeliski, Richard},
	pages = {979},
	file = {Szeliski - Computer Vision Algorithms and Applications.pdf:C\:\\Users\\bjoern\\Zotero\\storage\\43KYEMGE\\Szeliski - Computer Vision Algorithms and Applications.pdf:application/pdf}
}

@misc{noauthor_vapnikchervonenkis_2020,
	title = {Vapnik–{Chervonenkis} dimension},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Vapnik%E2%80%93Chervonenkis_dimension&oldid=942482212},
	abstract = {In Vapnik–Chervonenkis theory, the Vapnik–Chervonenkis (VC) dimension is a measure of the capacity (complexity, expressive power, richness, or flexibility) of a space of functions that can be learned by a statistical classification algorithm. It is defined as the cardinality of the largest set of points that the algorithm can shatter. It was originally defined by Vladimir Vapnik and Alexey Chervonenkis.Informally, the capacity of a classification model is related to how complicated it can be. For example, consider the thresholding of a high-degree polynomial: if the polynomial evaluates above zero, that point is classified as positive, otherwise as negative. A high-degree polynomial can be wiggly, so it can fit a given set of training points well. But one can expect that the classifier will make errors on other points, because it is too wiggly. Such a polynomial has a high capacity. A much simpler alternative is to threshold a linear function. This function may not fit the training set well, because it has a low capacity. This notion of capacity is made rigorous below.},
	language = {en},
	urldate = {2020-02-25},
	journal = {Wikipedia},
	month = feb,
	year = {2020},
	note = {Page Version ID: 942482212},
	file = {Snapshot:C\:\\Users\\bjoern\\Zotero\\storage\\RNYYQRHR\\index.html:text/html}
}

@misc{noauthor_overfitting_2020,
	title = {Overfitting},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Overfitting&oldid=942053730},
	abstract = {In statistics, overfitting is "the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit additional data or predict future observations reliably". An overfitted model is a statistical model that contains more parameters than can be justified by the data. The essence of overfitting is to have unknowingly extracted some of the residual variation (i.e. the noise) as if that variation represented underlying model structure.Underfitting occurs when a statistical model cannot adequately capture the underlying structure of the data. An underfitted model is a model where some parameters or terms that would appear in a correctly specified model are missing. Underfitting would occur, for example, when fitting a linear model to non-linear data. Such a model will tend to have poor predictive performance.
Overfitting and underfitting can occur in machine learning, in particular. In machine learning, the phenomena are sometimes called "overtraining" and "undertraining". 
The possibility of overfitting exists because the criterion used for selecting the model is not the same as the criterion used to judge the suitability of a model. For example, a model might be selected by maximizing its performance on some set of training data, and yet its suitability might be determined by its ability to perform well on unseen data; then overfitting occurs when a model begins to "memorize" training data rather than "learning" to generalize from a trend. 
As an extreme example, if the number of parameters is the same as or greater than the number of observations, then a model can perfectly predict the training data simply by memorizing the data in its entirety. (For an illustration, see Figure 2.) Such a model, though, will typically fail severely when making predictions. 
The potential for overfitting depends not only on the number of parameters and data but also the conformability of the model structure with the data shape, and the magnitude of model error compared to the expected level of noise or error in the data. Even when the fitted model does not have an excessive number of parameters, it is to be expected that the fitted relationship will appear to perform less well on a new data set than on the data set used for fitting (a phenomenon sometimes known as shrinkage). In particular, the value of the coefficient of determination will shrink relative to the original data.
To lessen the chance of, or amount of, overfitting, several techniques are available (e.g. model comparison, cross-validation, regularization, early stopping, pruning, Bayesian priors, or dropout). The basis of some techniques is either (1) to explicitly penalize overly complex models or (2) to test the model's ability to generalize by evaluating its performance on a set of data not used for training, which is assumed to approximate the typical unseen data that a model will encounter.},
	language = {en},
	urldate = {2020-02-25},
	journal = {Wikipedia},
	month = feb,
	year = {2020},
	note = {Page Version ID: 942053730},
	file = {Snapshot:C\:\\Users\\bjoern\\Zotero\\storage\\LIR4PH8P\\index.html:text/html}
}

@misc{noauthor_perceptron_2020,
	title = {Perceptron},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Perceptron&oldid=942271496},
	abstract = {In machine learning, the perceptron is an algorithm for supervised learning of binary classifiers.  A binary classifier is a function which can decide whether or not an input, represented by a vector of numbers, belongs to some specific class.  It is a type of linear classifier, i.e. a classification algorithm that makes its predictions based on a linear predictor function combining a set of weights with the feature vector.},
	language = {en},
	urldate = {2020-02-25},
	journal = {Wikipedia},
	month = feb,
	year = {2020},
	note = {Page Version ID: 942271496},
	file = {Snapshot:C\:\\Users\\bjoern\\Zotero\\storage\\F9CJN728\\index.html:text/html}
}

@misc{noauthor_least_2020,
	title = {Least mean squares filter},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Least_mean_squares_filter&oldid=941899198},
	abstract = {Least mean squares (LMS) algorithms are a class of adaptive filter used to mimic a desired filter by finding the filter coefficients that relate to producing the least mean square of the error signal (difference between the desired and the actual signal). It is a stochastic gradient descent method in that the filter is only adapted based on the error at the current time.  It was invented in 1960 by Stanford University professor Bernard Widrow and his first Ph.D. student, Ted Hoff.},
	language = {en},
	urldate = {2020-02-25},
	journal = {Wikipedia},
	month = feb,
	year = {2020},
	note = {Page Version ID: 941899198},
	file = {Snapshot:C\:\\Users\\bjoern\\Zotero\\storage\\4MDVNMAZ\\index.html:text/html}
}

@misc{noauthor_backpropagation_2020,
	title = {Backpropagation},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Backpropagation&oldid=939314095},
	abstract = {In machine learning, specifically deep learning, backpropagation (backprop, BP) is a widely used algorithm in training feedforward neural networks for supervised learning. Generalizations of backpropagation exist for other artificial neural networks (ANNs), and for functions generally – a class of algorithms is referred to generically as "backpropagation". In deep learning, backpropagation computes the gradient of the loss function with respect to the weights of the network for a single input–output example, and does so efficiently, unlike a naive direct computation of the gradient with respect to each weight individually. This efficiency makes it feasible to use gradient methods for training multilayer networks, updating weights to minimize loss; gradient descent, or variants such as stochastic gradient descent, are commonly used. The backpropagation algorithm works by computing the gradient of the loss function with respect to each weight by the chain rule, computing the gradient one layer at a time, iterating backward from the last layer to avoid redundant calculations of intermediate terms in the chain rule; this is an example of dynamic programming.The term backpropagation strictly refers only to the algorithm for computing the gradient, not how the gradient is used; but the term is often used loosely to refer to the entire learning algorithm, including how the gradient is used, such as by stochastic gradient descent. Backpropagation generalizes the gradient computation in the Delta rule, which is the single-layer version of backpropagation, and is in turn generalized by automatic differentiation, where backpropagation is a special case of reverse accumulation (or "reverse mode"). The term backpropagation and its general use in neural networks was announced in Rumelhart, Hinton \& Williams (1986a), then elaborated and popularized in Rumelhart, Hinton \& Williams (1986b), but the technique was independently rediscovered many times, and had many predecessors dating to the 1960s; see § History. A modern overview is given in Goodfellow, Bengio \& Courville (2016).},
	language = {en},
	urldate = {2020-02-25},
	journal = {Wikipedia},
	month = feb,
	year = {2020},
	note = {Page Version ID: 939314095},
	file = {Snapshot:C\:\\Users\\bjoern\\Zotero\\storage\\KNCN5VTB\\index.html:text/html}
}

@misc{noauthor_confusion_2020,
	title = {Confusion matrix},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Confusion_matrix&oldid=940280604},
	abstract = {In the field of machine learning and specifically the problem of statistical classification, a confusion matrix, also known as an error matrix, is a specific table layout that allows visualization of the performance of an algorithm, typically a supervised learning one (in unsupervised learning it is usually called a matching matrix). Each row of the matrix represents the instances in a predicted class while each column represents the instances in an actual class (or vice versa). The name stems from the fact that it makes it easy to see if the system is confusing two classes (i.e. commonly mislabeling one as another).
It is a special kind of contingency table, with two dimensions ("actual" and "predicted"), and identical sets of "classes" in both dimensions (each combination of dimension and class is a variable in the contingency table).},
	language = {en},
	urldate = {2020-02-25},
	journal = {Wikipedia},
	month = feb,
	year = {2020},
	note = {Page Version ID: 940280604},
	file = {Snapshot:C\:\\Users\\bjoern\\Zotero\\storage\\ERMSAH8U\\index.html:text/html}
}

@misc{noauthor_verlustfunktion_2018,
	title = {Verlustfunktion ({Statistik})},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://de.wikipedia.org/w/index.php?title=Verlustfunktion_(Statistik)&oldid=177095272},
	abstract = {Eine Verlustfunktion ist eine spezielle Funktion in der mathematischen Statistik und Teil eines statistischen Entscheidungsproblemes. Sie ordnet jeder Entscheidung in Form einer Punktschätzung, einer Bereichsschätzung oder eines Tests den Schaden zu, der durch eine vom wahren Parameter abweichende Entscheidung entsteht. Gemeinsam mit der Entscheidungsfunktion wird die Verlustfunktion zur Risikofunktion kombiniert, die den potentiellen Schaden bei Verwendung einer Entscheidungsfunktion angibt.},
	language = {de},
	urldate = {2020-02-26},
	journal = {Wikipedia},
	month = may,
	year = {2018},
	note = {Page Version ID: 177095272},
	file = {Snapshot:C\:\\Users\\bjoern\\Zotero\\storage\\NYCJQ5AS\\index.html:text/html}
}

@misc{noauthor_imagenet_2019,
	title = {{ImageNet}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=ImageNet&oldid=929993952},
	abstract = {The ImageNet project is a large visual database designed for use in visual object recognition software research. More than 14 million images have been hand-annotated by the project to indicate what objects are pictured and in at least one million of the images, bounding boxes are also provided. ImageNet contains more than 20,000 categories with a typical category, such as "balloon" or "strawberry", consisting of several hundred images. The database of annotations of third-party image URLs is freely available directly from ImageNet, though the actual images are not owned by ImageNet. Since 2010, the ImageNet project runs an annual software contest, the ImageNet Large Scale Visual Recognition Challenge (ILSVRC), where software programs compete to correctly classify and detect objects and scenes. The challenge uses a "trimmed" list of one thousand non-overlapping classes.},
	language = {en},
	urldate = {2020-02-28},
	journal = {Wikipedia},
	month = dec,
	year = {2019},
	note = {Page Version ID: 929993952},
	file = {Snapshot:C\:\\Users\\bjoern\\Zotero\\storage\\MTEDIEDT\\index.html:text/html}
}

@misc{seif_deep_2019,
	title = {Deep {Learning} for {Image} {Recognition}: why it’s challenging, where we’ve been, and what’s next},
	shorttitle = {Deep {Learning} for {Image} {Recognition}},
	url = {https://towardsdatascience.com/deep-learning-for-image-classification-why-its-challenging-where-we-ve-been-and-what-s-next-93b56948fcef},
	abstract = {Deep learning has absolutely dominated computer vision over the last few years, achieving top scores on many tasks and their related…},
	language = {en},
	urldate = {2020-02-28},
	journal = {Medium},
	author = {Seif, George},
	month = may,
	year = {2019},
	note = {Library Catalog: towardsdatascience.com},
	file = {Snapshot:C\:\\Users\\bjoern\\Zotero\\storage\\393GVRX7\\deep-learning-for-image-classification-why-its-challenging-where-we-ve-been-and-what-s-next-93b.html:text/html}
}

@misc{noauthor_machine_2020,
	title = {Machine learning},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Machine_learning&oldid=942989288},
	abstract = {Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to perform a specific task without using explicit instructions, relying on patterns and inference instead. It is seen as a subset of artificial intelligence. Machine learning algorithms build a mathematical model based on sample data, known as "training data", in order to make predictions or decisions without being explicitly programmed to perform the task. Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or infeasible to develop a conventional algorithm for effectively performing the task.
Machine learning is closely related to computational statistics, which focuses on making predictions using computers. The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a field of study within machine learning, and focuses on exploratory data analysis through unsupervised learning. In its application across business problems, machine learning is also referred to as predictive analytics.},
	language = {en},
	urldate = {2020-02-28},
	journal = {Wikipedia},
	month = feb,
	year = {2020},
	note = {Page Version ID: 942989288},
	file = {Snapshot:C\:\\Users\\bjoern\\Zotero\\storage\\67JRX4IU\\index.html:text/html}
}

@misc{noauthor_deep_2020,
	title = {Deep learning},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Deep_learning&oldid=942561541},
	abstract = {Deep learning  (also known as deep structured learning or differential programming) is part of a broader family of machine learning methods based on artificial neural networks with representation learning. Learning can be supervised, semi-supervised or unsupervised.Deep learning architectures such as deep neural networks, deep belief networks, recurrent neural networks and convolutional neural networks have been applied to fields including computer vision, speech recognition, natural language processing, audio recognition, social network filtering, machine translation, bioinformatics, drug design, medical image analysis, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.Artificial neural networks (ANNs) were inspired by information processing and distributed communication nodes in biological systems. ANNs have various differences from biological brains.  Specifically, neural networks tend to be static and symbolic, while the biological brain of most living organisms is dynamic (plastic) and analog.},
	language = {en},
	urldate = {2020-02-28},
	journal = {Wikipedia},
	month = feb,
	year = {2020},
	note = {Page Version ID: 942561541},
	file = {Snapshot:C\:\\Users\\bjoern\\Zotero\\storage\\WFQE6LKN\\index.html:text/html}
}

@misc{noauthor_k-nearest_2020,
	title = {k-nearest neighbors algorithm},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=K-nearest_neighbors_algorithm&oldid=942113305},
	abstract = {In pattern recognition, the k-nearest neighbors algorithm (k-NN) is a non-parametric method used for classification and regression. In both cases, the input consists of the k closest training examples in the feature space. The output depends on whether k-NN is used for classification or regression:

In k-NN classification, the output is a class membership. An object is classified by a plurality vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). If k = 1, then the object is simply assigned to the class of that single nearest neighbor.In k-NN regression, the output is the property value for the object. This value is the average of the values of k nearest neighbors.k-NN is a type of instance-based learning, or lazy learning, where the function is only approximated locally and all computation is deferred until function evaluation.
Both for classification and regression, a useful technique can be to assign weights to the contributions of the neighbors, so that the nearer neighbors contribute more to the average than the more distant ones. For example, a common weighting scheme consists in giving each neighbor a weight of 1/d, where d is the distance to the neighbor.The neighbors are taken from a set of objects for which the class (for k-NN classification) or the object property value (for k-NN regression) is known. This can be thought of as the training set for the algorithm, though no explicit training step is required.
A peculiarity of the k-NN algorithm is that it is sensitive to the local structure of the data.},
	language = {en},
	urldate = {2020-02-28},
	journal = {Wikipedia},
	month = feb,
	year = {2020},
	note = {Page Version ID: 942113305},
	file = {Snapshot:C\:\\Users\\bjoern\\Zotero\\storage\\ZHFE5HS3\\index.html:text/html}
}

@misc{noauthor_linear_2020,
	title = {Linear regression},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Linear_regression&oldid=935782381},
	abstract = {In statistics, linear regression is a linear approach to modeling the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables). The case of one explanatory variable is called simple linear regression. For more than one explanatory variable, the process is called multiple linear regression. This term is distinct from multivariate linear regression, where multiple correlated dependent variables are predicted, rather than a single scalar variable.In linear regression, the relationships are modeled using linear predictor functions whose unknown model parameters are estimated from the data. Such models are called linear models. Most commonly, the conditional mean of the response given the values of the explanatory variables (or predictors) is assumed to be an affine function of those values; less commonly, the conditional median or some other quantile is used. Like all forms of regression analysis, linear regression focuses on the conditional probability distribution of the response given the values of the predictors, rather than on the joint probability distribution of all of these variables, which is the domain of multivariate analysis.
Linear regression was the first type of regression analysis to be studied rigorously, and to be used extensively in practical applications. This is because models which depend linearly on their unknown parameters are easier to fit than models which are non-linearly related to their parameters and because the statistical properties of the resulting estimators are easier to determine.
Linear regression has many practical uses. Most applications fall into one of the following two broad categories:

If the goal is prediction, forecasting, or error reduction, linear regression can be used to fit a predictive model to an observed data set of values of the response and explanatory variables. After developing such a model, if additional values of the explanatory variables are collected without an accompanying response value, the fitted model can be used to make a prediction of the response.
If the goal is to explain variation in the response variable that can be attributed to variation in the explanatory variables, linear regression analysis can be applied to quantify the strength of the relationship between the response and the explanatory variables, and in particular to determine whether some explanatory variables may have no linear relationship with the response at all, or to identify which subsets of explanatory variables may contain redundant information about the response.Linear regression models are often fitted using the least squares approach, but they may also be fitted in other ways, such as by minimizing the "lack of fit" in some other norm (as with least absolute deviations regression), or by minimizing a penalized version of the least squares cost function as in ridge regression (L2-norm penalty) and lasso (L1-norm penalty). Conversely, the least squares approach can be used to fit models that are not linear models. Thus, although the terms "least squares" and "linear model" are closely linked, they are not synonymous.},
	language = {en},
	urldate = {2020-02-28},
	journal = {Wikipedia},
	month = jan,
	year = {2020},
	note = {Page Version ID: 935782381},
	file = {Snapshot:C\:\\Users\\bjoern\\Zotero\\storage\\BGQBFDMV\\index.html:text/html}
}

@misc{noauthor_support-vector_2020,
	title = {Support-vector machine},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Support-vector_machine&oldid=942477636},
	abstract = {In machine learning, support-vector machines (SVMs, also support-vector networks) are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis.  Given a set of training examples, each marked as belonging to one or the other of two categories, an SVM training algorithm builds a model that assigns new examples to one category or the other, making it a non-probabilistic binary linear classifier (although methods such as Platt scaling exist to use SVM in a probabilistic classification setting). An SVM model is a representation of the examples as points in space, mapped so that the examples of the separate categories are divided by a clear gap that is as wide as possible. New examples are then mapped into that same space and predicted to belong to a category based on the side of the gap on which they fall.
In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces.
When data are unlabelled, supervised learning is not possible, and an unsupervised learning approach is required, which attempts to find natural clustering of the data to groups, and then map new data to these formed groups. The support-vector clustering algorithm, created by Hava Siegelmann and Vladimir Vapnik, applies the statistics of support vectors, developed in the support vector machines algorithm, to categorize unlabeled data, and is one of the most widely used clustering algorithms in industrial applications.},
	language = {en},
	urldate = {2020-02-28},
	journal = {Wikipedia},
	month = feb,
	year = {2020},
	note = {Page Version ID: 942477636},
	file = {Snapshot:C\:\\Users\\bjoern\\Zotero\\storage\\7S6T4VDE\\index.html:text/html}
}

@misc{noauthor_random_2020,
	title = {Random forest},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Random_forest&oldid=938369502},
	abstract = {Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Random decision forests correct for decision trees' habit of overfitting to their training set.The first algorithm for random decision forests was created by Tin Kam Ho using the random subspace method, which, in Ho's formulation, is a way to implement the "stochastic discrimination" approach to classification proposed by Eugene Kleinberg.An extension of the algorithm was developed by Leo Breiman and Adele Cutler, who registered "Random Forests" as a trademark (as of 2019, owned by Minitab, Inc.). The extension combines Breiman's "bagging" idea and random selection of features, introduced first by Ho and later independently by Amit and Geman in order to construct a collection of decision trees with controlled variance.},
	language = {en},
	urldate = {2020-02-28},
	journal = {Wikipedia},
	month = jan,
	year = {2020},
	note = {Page Version ID: 938369502},
	file = {Snapshot:C\:\\Users\\bjoern\\Zotero\\storage\\XEZU7HLR\\index.html:text/html}
}

@misc{noauthor_k-means_2020,
	title = {k-means clustering},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=K-means_clustering&oldid=942500957},
	abstract = {k-means clustering is a method of vector quantization, originally from signal processing, that is popular for cluster analysis in data mining. k-means clustering aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean, serving as a prototype of the cluster. This results in a partitioning of the data space into Voronoi cells. k-Means minimizes within-cluster variances (squared Euclidean distances), but not regular Euclidean distances, which would be the more difficult Weber problem: the mean optimizes squared errors, whereas only the geometric median minimizes Euclidean distances. Better Euclidean solutions can for example be found using k-medians and k-medoids.
The problem is computationally difficult (NP-hard); however, efficient heuristic algorithms converge quickly to a local optimum. These are usually similar to the expectation-maximization algorithm for mixtures of Gaussian distributions via an iterative refinement approach employed by both k-means and Gaussian mixture modeling. They both use cluster centers to model the data; however, k-means clustering tends to find clusters of comparable spatial extent, while the expectation-maximization mechanism allows clusters to have different shapes.
The algorithm has a loose relationship to the k-nearest neighbor classifier, a popular machine learning technique for classification that is often confused with k-means due to the name. Applying the 1-nearest neighbor classifier to the cluster centers obtained by k-means classifies new data into the existing clusters. This is known as nearest centroid classifier or Rocchio algorithm.},
	language = {en},
	urldate = {2020-02-28},
	journal = {Wikipedia},
	month = feb,
	year = {2020},
	note = {Page Version ID: 942500957},
	file = {Snapshot:C\:\\Users\\bjoern\\Zotero\\storage\\T83H5YM5\\index.html:text/html}
}

@misc{noauthor_hierarchical_2020,
	title = {Hierarchical clustering},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Hierarchical_clustering&oldid=934548831},
	abstract = {In data mining and statistics, hierarchical clustering (also called hierarchical cluster analysis or HCA) is a method of cluster analysis which seeks to build a hierarchy of clusters. Strategies for hierarchical clustering generally fall into two types:
Agglomerative: This is a "bottom-up" approach: each observation starts in its own cluster, and pairs of clusters are merged as one moves up the hierarchy.
Divisive: This is a "top-down" approach: all observations start in one cluster, and splits are performed recursively as one moves down the hierarchy.In general, the merges and splits are determined in a greedy manner. The results of hierarchical clustering are usually presented in a dendrogram.
The standard algorithm for hierarchical agglomerative clustering (HAC) has a time complexity of 
  
    
      
        
          
            O
          
        
        (
        
          n
          
            3
          
        
        )
      
    
    \{{\textbackslash}displaystyle \{{\textbackslash}mathcal \{O\}\}(n{\textasciicircum}\{3\})\}
   and requires 
  
    
      
        
          
            O
          
        
        (
        
          n
          
            2
          
        
        )
      
    
    \{{\textbackslash}displaystyle \{{\textbackslash}mathcal \{O\}\}(n{\textasciicircum}\{2\})\}
   memory, which makes it too slow for even medium data sets. However, for some special cases, optimal efficient agglomerative methods (of complexity 
  
    
      
        
          
            O
          
        
        (
        
          n
          
            2
          
        
        )
      
    
    \{{\textbackslash}displaystyle \{{\textbackslash}mathcal \{O\}\}(n{\textasciicircum}\{2\})\}
  ) are known: SLINK for single-linkage and CLINK for complete-linkage clustering. With a heap the runtime of the general case can be reduced to 
  
    
      
        
          
            O
          
        
        (
        
          n
          
            2
          
        
        log
        ⁡
        n
        )
      
    
    \{{\textbackslash}displaystyle \{{\textbackslash}mathcal \{O\}\}(n{\textasciicircum}\{2\}{\textbackslash}log n)\}
   at the cost of further increasing the memory requirements. In many cases, the memory overheads of this approach are too large to make it practically usable.
Except for the special case of single-linkage, none of the algorithms (except exhaustive search in 
  
    
      
        
          
            O
          
        
        (
        
          2
          
            n
          
        
        )
      
    
    \{{\textbackslash}displaystyle \{{\textbackslash}mathcal \{O\}\}(2{\textasciicircum}\{n\})\}
  ) can be guaranteed to find the optimum solution.
Divisive clustering with an exhaustive search is 
  
    
      
        
          
            O
          
        
        (
        
          2
          
            n
          
        
        )
      
    
    \{{\textbackslash}displaystyle \{{\textbackslash}mathcal \{O\}\}(2{\textasciicircum}\{n\})\}
  , but it is common to use faster heuristics to choose splits, such as k-means.},
	language = {en},
	urldate = {2020-02-28},
	journal = {Wikipedia},
	month = jan,
	year = {2020},
	note = {Page Version ID: 934548831},
	file = {Snapshot:C\:\\Users\\bjoern\\Zotero\\storage\\D4GQC7QI\\index.html:text/html}
}

@misc{noauthor_expectationmaximization_2020,
	title = {Expectation–maximization algorithm},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Expectation%E2%80%93maximization_algorithm&oldid=936223068},
	abstract = {In statistics, an expectation–maximization (EM) algorithm is an iterative method to find maximum likelihood or maximum a posteriori (MAP) estimates of parameters in statistical models, where the model depends on unobserved latent variables. The EM iteration alternates between performing an expectation (E) step, which creates a function for the expectation of the log-likelihood evaluated using the current estimate for the parameters, and a maximization (M) step, which computes parameters maximizing the expected log-likelihood found on the E step. These parameter-estimates are then used to determine the distribution of the latent variables in the next E step.},
	language = {en},
	urldate = {2020-02-28},
	journal = {Wikipedia},
	month = jan,
	year = {2020},
	note = {Page Version ID: 936223068},
	file = {Snapshot:C\:\\Users\\bjoern\\Zotero\\storage\\QI4AITPE\\index.html:text/html}
}

@misc{noauthor_logistic_2020,
	title = {Logistic regression},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Logistic_regression&oldid=941157282},
	abstract = {In statistics, the logistic model (or logit model) is used to model the probability of a certain class or event existing such as pass/fail, win/lose, alive/dead or healthy/sick.  This can be extended to model several classes of events such as determining whether an image contains a cat, dog, lion, etc.  Each object being detected in the image would be assigned a probability between 0 and 1 and the sum adding to one.
Logistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable, although many more complex extensions exist. In regression analysis, logistic regression (or logit regression) is estimating the parameters of a logistic model (a form of binary regression). Mathematically, a binary logistic model has a dependent variable with two possible values, such as pass/fail which is represented by an indicator variable, where the two values are labeled "0" and "1". In the logistic model, the log-odds (the logarithm of the odds) for the value labeled "1" is a linear combination of one or more independent variables ("predictors"); the independent variables can each be a binary variable (two classes, coded by an indicator variable) or a continuous variable (any real value). The corresponding probability of the value labeled "1" can vary between 0 (certainly the value "0") and 1 (certainly the value "1"), hence the labeling; the function that converts log-odds to probability is the logistic function, hence the name. The unit of measurement for the log-odds scale is called a logit, from logistic unit, hence the alternative names. Analogous models with a different sigmoid function instead of the logistic function can also be used, such as the probit model; the defining characteristic of the logistic model is that increasing one of the independent variables multiplicatively scales the odds of the given outcome at a constant rate, with each independent variable having its own parameter; for a binary dependent variable this generalizes the odds ratio.
In a binary logistic regression model, the dependent variable has two levels (categorical). Outputs with more than two values are modeled by multinomial logistic regression and, if the multiple categories are ordered, by ordinal logistic regression (for example the proportional odds ordinal logistic model). The logistic regression model itself simply models probability of output in terms of input and does not perform statistical classification (it is not a classifier), though it can be used to make a classifier, for instance by choosing a cutoff value and classifying inputs with probability greater than the cutoff as one class, below the cutoff as the other; this is a common way to make a binary classifier. The coefficients are generally not computed by a closed-form expression, unlike linear least squares; see § Model fitting. The logistic regression as a general statistical model was originally developed and popularized primarily by Joseph Berkson, beginning in Berkson (1944), where he coined "logit"; see § History.},
	language = {en},
	urldate = {2020-02-28},
	journal = {Wikipedia},
	month = feb,
	year = {2020},
	note = {Page Version ID: 941157282},
	file = {Snapshot:C\:\\Users\\bjoern\\Zotero\\storage\\CY48R7I9\\index.html:text/html}
}